import streamlit as st
import pandas as pd
import re
from utils.mcp_client import MCPClient
from utils.config_manager import ConfigManager
from utils.llm_client import LLMClient
from utils.i18n import t
from utils.test_question_helper import render_test_question_sidebar, get_test_question_input
from utils.mcp_tool_handler import get_llm_tools, handle_tool_calls

def clean_sql_response(sql_text):
    """æ¸…ç†LLMå“åº”ä¸­çš„SQLï¼Œå»æ‰å¤šä½™çš„è§£é‡Šå†…å®¹"""
    if not sql_text:
        return sql_text
    
    lines = sql_text.strip().split('\n')
    sql_lines = []
    
    for line in lines:
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œ
        if not line:
            continue
            
        # è·³è¿‡æ˜æ˜¾çš„è§£é‡Šæ€§æ–‡å­—ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰
        if (line.startswith('ä¸‹é¢çš„') or line.startswith('ä»¥ä¸‹') or 
            line.startswith('This query') or line.startswith('The following') or
            line.startswith('è¿™ä¸ª') or line.startswith('è¯¥') or
            'ä¼šç»Ÿè®¡' in line or 'will calculate' in line or
            'æŒ‰.*æ’åˆ—' in line or 'ordered by' in line.lower() or
            line.startswith('æ³¨æ„ï¼š') or line.startswith('Note:')):
            continue
            
        # è·³è¿‡çº¯ä¸­æ–‡è§£é‡Šè¡Œï¼ˆä¸åŒ…å«SQLå…³é”®å­—ï¼‰
        if (re.match(r'^[^\x00-\x7Fï¼Œã€‚ï¼šï¼›ï¼ï¼Ÿï¼ˆï¼‰ã€ã€‘""''ã€]+[ï¼Œã€‚ï¼šï¼›ï¼ï¼Ÿ]*$', line) and
            not any(keyword in line.upper() for keyword in 
                   ['SELECT', 'FROM', 'WHERE', 'GROUP', 'ORDER', 'INSERT', 'UPDATE', 'DELETE'])):
            continue
            
        # ä¿ç•™SQLè¯­å¥è¡Œ
        sql_lines.append(line)
    
    # é‡æ–°ç»„åˆSQL
    cleaned_sql = '\n'.join(sql_lines).strip()
    
    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè¿”å›åŸæ–‡
    if not cleaned_sql:
        return sql_text
        
    return cleaned_sql

def execute_analysis_plan_steps(analysis_plan, original_question, database_type, config_manager, llm_client, mcp_client, db_config, check_dangerous_sql):
    """
    æŒ‰æ­¥éª¤æ‰§è¡Œåˆ†æè®¡åˆ’
    
    Args:
        analysis_plan: åˆ†æè®¡åˆ’å¯¹è±¡
        original_question: åŸå§‹é—®é¢˜
        database_type: æ•°æ®åº“ç±»å‹
        config_manager: é…ç½®ç®¡ç†å™¨
        llm_client: LLMå®¢æˆ·ç«¯
        mcp_client: MCPå®¢æˆ·ç«¯
        db_config: æ•°æ®åº“é…ç½®
        check_dangerous_sql: å±é™©SQLæ£€æŸ¥å‡½æ•°
    """
    
    st.markdown("[æ„å›¾è¯†åˆ«] **åˆ†ææ„å›¾ - æ‰§è¡Œé˜¶æ®µ** ğŸš€")
    st.success(f"å¼€å§‹æ‰§è¡Œåˆ†æè®¡åˆ’: {original_question}")
    
    # è·å–è®¡åˆ’å†…å®¹
    if isinstance(analysis_plan, dict) and analysis_plan.get('format') == 'json':
        plan_content = analysis_plan['content']
    else:
        st.error("åˆ†æè®¡åˆ’æ ¼å¼ä¸æ­£ç¡®")
        return
    
    if isinstance(plan_content, str):
        import json
        try:
            plan_content = json.loads(plan_content)
        except json.JSONDecodeError:
            st.error("æ— æ³•è§£æåˆ†æè®¡åˆ’JSON")
            return
    
    # æ˜¾ç¤ºæ‰§è¡Œæ¦‚è§ˆ
    steps = plan_content.get('steps', [])
    st.info(f"ğŸ“‹ æ‰§è¡Œè®¡åˆ’æ¦‚è§ˆ: å…±{len(steps)}ä¸ªæ­¥éª¤")
    
    # å­˜å‚¨æ¯ä¸ªæ­¥éª¤çš„ç»“æœ
    step_results = {}
    execution_log = []
    
    # æŒ‰step_idæ’åºæ‰§è¡Œ
    sorted_steps = sorted(steps, key=lambda x: x.get('step_id', 0))
    
    for i, step in enumerate(sorted_steps):
        step_id = step.get('step_id', i+1)
        step_type = step.get('step_type', 'unknown')
        description = step.get('description', 'æœªçŸ¥æ­¥éª¤')
        dependencies = step.get('dependencies', [])
        
        # æ£€æŸ¥ä¾èµ–å…³ç³»
        if dependencies:
            missing_deps = [dep for dep in dependencies if dep not in step_results]
            if missing_deps:
                error_msg = f"æ­¥éª¤{step_id}ä¾èµ–çš„æ­¥éª¤{missing_deps}å°šæœªå®Œæˆï¼Œè·³è¿‡æ‰§è¡Œ"
                st.warning(error_msg)
                execution_log.append(f"âš ï¸ {error_msg}")
                continue
        
        # æ˜¾ç¤ºå½“å‰æ­¥éª¤
        with st.expander(f"ğŸ”„ æ‰§è¡Œæ­¥éª¤ {step_id}: {description}", expanded=True):
            st.write(f"**æ­¥éª¤ç±»å‹**: {step_type}")
            
            try:
                if step_type == 'sql_query':
                    result = execute_sql_query_step(step, database_type, config_manager, llm_client, mcp_client, db_config, check_dangerous_sql)
                elif step_type == 'external_data':
                    result = execute_external_data_step(step, mcp_client)
                elif step_type == 'llm_analysis':
                    result = execute_llm_analysis_step(step, step_results, llm_client, original_question)
                else:
                    result = {'status': 'error', 'message': f'ä¸æ”¯æŒçš„æ­¥éª¤ç±»å‹: {step_type}'}
                
                # å­˜å‚¨ç»“æœ
                step_results[step_id] = result
                
                # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                if result.get('status') == 'success':
                    st.success(f"âœ… æ­¥éª¤{step_id}æ‰§è¡ŒæˆåŠŸ")
                    execution_log.append(f"âœ… æ­¥éª¤{step_id}: {description} - æ‰§è¡ŒæˆåŠŸ")
                    
                    # æ˜¾ç¤ºå…·ä½“ç»“æœ
                    if 'data' in result and result['data'] is not None:
                        if isinstance(result['data'], pd.DataFrame):
                            st.dataframe(result['data'])
                        else:
                            st.write("**ç»“æœæ•°æ®**:", result['data'])
                    
                    if 'message' in result:
                        st.write("**æ‰§è¡Œè¯¦æƒ…**:", result['message'])
                        
                else:
                    st.error(f"âŒ æ­¥éª¤{step_id}æ‰§è¡Œå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    execution_log.append(f"âŒ æ­¥éª¤{step_id}: {description} - æ‰§è¡Œå¤±è´¥: {result.get('message')}")
                    
            except Exception as e:
                error_msg = f"æ­¥éª¤{step_id}æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                st.error(error_msg)
                execution_log.append(f"ğŸ’¥ {error_msg}")
                step_results[step_id] = {'status': 'error', 'message': str(e)}
    
    # ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š
    generate_final_analysis_report(plan_content, step_results, execution_log, original_question)
    
    # æ¸…é™¤åˆ†æè®¡åˆ’çŠ¶æ€
    st.session_state.analysis_plan = None
    st.session_state.analysis_question = None
    
    # æ·»åŠ æ‰§è¡Œæ—¥å¿—åˆ°æ¶ˆæ¯å†å²
    log_summary = "\n".join(execution_log)
    final_message = f"[åˆ†ææ‰§è¡Œå®Œæˆ] {original_question}\n\næ‰§è¡Œæ—¥å¿—:\n{log_summary}"
    st.session_state.messages.append({"role": "assistant", "content": final_message})

def execute_sql_query_step(step, database_type, config_manager, llm_client, mcp_client, db_config, check_dangerous_sql):
    """æ‰§è¡ŒSQLæŸ¥è¯¢æ­¥éª¤"""
    query_requirements = step.get('query_requirements', {})
    
    # æ ¹æ®æŸ¥è¯¢éœ€æ±‚æ„å»ºprompt
    sql_prompt = f"""æ ¹æ®ä»¥ä¸‹æŸ¥è¯¢éœ€æ±‚ç”ŸæˆSQLè¯­å¥ï¼š

è¡¨: {', '.join(query_requirements.get('tables', []))}
æ—¶é—´èŒƒå›´: {query_requirements.get('time_range', 'ä¸é™')}
ç­›é€‰æ¡ä»¶: {', '.join(query_requirements.get('filters', []))}
éœ€è¦çš„æŒ‡æ ‡: {', '.join(query_requirements.get('metrics', []))}
åˆ†ç»„ç»´åº¦: {', '.join(query_requirements.get('grouping', []))}

è¯·åªè¿”å›å¯æ‰§è¡Œçš„SQLè¯­å¥ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šè¯´æ˜ã€‚"""
    
    try:
        # ç”ŸæˆSQL
        with st.spinner("ç”ŸæˆSQLæŸ¥è¯¢..."):
            sql = llm_client.generate_sql(sql_prompt)
            sql = clean_sql_response(sql) if sql else None
        
        if not sql:
            return {'status': 'error', 'message': 'æ— æ³•ç”ŸæˆSQLæŸ¥è¯¢'}
        
        st.code(sql, language='sql')
        
        # æ£€æµ‹å±é™©SQLæ“ä½œ
        if check_dangerous_sql:
            is_dangerous, dangerous_keyword = check_dangerous_sql_operations(sql)
            if is_dangerous:
                return {'status': 'error', 'message': f'æ£€æµ‹åˆ°å±é™©æ“ä½œ: {dangerous_keyword}'}
        
        # æ‰§è¡ŒæŸ¥è¯¢
        with st.spinner("æ‰§è¡ŒSQLæŸ¥è¯¢..."):
            query_result = mcp_client.call_mcp_server_with_config(
                database_type,
                "execute_query", 
                db_config,
                {"sql": sql, "database": db_config.get("database")}
            )
        
        if "error" in query_result:
            return {'status': 'error', 'message': f'æŸ¥è¯¢å¤±è´¥: {query_result["error"]}'}
        
        if "result" in query_result and "data" in query_result["result"]:
            columns = query_result["result"]["data"].get("columns", [])
            rows = query_result["result"]["data"].get("rows", [])
            
            if rows:
                df = pd.DataFrame(rows, columns=columns)
                return {
                    'status': 'success',
                    'data': df,
                    'message': f'æŸ¥è¯¢æˆåŠŸï¼Œè·å¾—{len(rows)}è¡Œæ•°æ®',
                    'sql': sql
                }
            else:
                return {
                    'status': 'success', 
                    'data': None,
                    'message': 'æŸ¥è¯¢æˆåŠŸï¼Œä½†ç»“æœä¸ºç©º',
                    'sql': sql
                }
        else:
            return {'status': 'error', 'message': 'æŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®'}
            
    except Exception as e:
        return {'status': 'error', 'message': f'SQLæ‰§è¡Œå¼‚å¸¸: {str(e)}'}

def execute_external_data_step(step, mcp_client):
    """æ‰§è¡Œå¤–éƒ¨æ•°æ®è·å–æ­¥éª¤"""
    data_requirements = step.get('data_requirements', {})
    
    data_type = data_requirements.get('data_type', '')
    content_focus = data_requirements.get('content_focus', '')
    time_scope = data_requirements.get('time_scope', '')
    geographic_scope = data_requirements.get('geographic_scope', '')
    
    # æ„å»ºæœç´¢æŸ¥è¯¢
    search_query = f"{data_type} {content_focus}"
    if time_scope:
        search_query += f" {time_scope}"
    if geographic_scope:
        search_query += f" {geographic_scope}"
    
    try:
        with st.spinner(f"è·å–å¤–éƒ¨æ•°æ®: {search_query}..."):
            st.write(f"ğŸ” æœç´¢å…³é”®è¯: {search_query}")
            
            # æ¨¡æ‹Ÿå¤–éƒ¨æ•°æ®è·å–ï¼ˆå®é™…é¡¹ç›®ä¸­å¯ä»¥é›†æˆçœŸå®çš„æ•°æ®æºï¼‰
            # ç”±äºplaywrightéœ€è¦å¼‚æ­¥ç¯å¢ƒä¸”è¾ƒå¤æ‚ï¼Œè¿™é‡Œå…ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            
            # æ ¹æ®æ•°æ®ç±»å‹è¿”å›æ¨¡æ‹Ÿçš„å¤–éƒ¨æ•°æ®
            if "å¤©æ°”" in data_type:
                external_data = {
                    'data_type': 'å¤©æ°”æ•°æ®',
                    'source': 'æ¨¡æ‹Ÿå¤©æ°”API',
                    'summary': f'æ ¹æ®{geographic_scope}åœ°åŒº{time_scope}çš„å¤©æ°”æ•°æ®åˆ†æ',
                    'key_findings': [
                        'å¹³å‡æ¸©åº¦: 22Â°C',
                        'é™é›¨å¤©æ•°: 8å¤©',
                        'æ¹¿åº¦: 65%',
                        'ä¸»è¦å¤©æ°”æ¨¡å¼: å¤šäº‘é—´æ™´'
                    ],
                    'search_query': search_query
                }
            elif "å¸‚åœº" in data_type or "ç»æµ" in data_type:
                external_data = {
                    'data_type': 'å¸‚åœºæ•°æ®',
                    'source': 'æ¨¡æ‹Ÿå¸‚åœºç ”ç©¶',
                    'summary': f'å…³äº{content_focus}çš„å¸‚åœºåˆ†ææ•°æ®',
                    'key_findings': [
                        'å¸‚åœºå¢é•¿ç‡: +12%',
                        'ä¸»è¦è¶‹åŠ¿: æ•°å­—åŒ–è½¬å‹',
                        'æ¶ˆè´¹è€…åå¥½: ä¾¿åˆ©æ€§ä¼˜å…ˆ',
                        'ç«äº‰æ ¼å±€: å¤´éƒ¨ä¼ä¸šé›†ä¸­'
                    ],
                    'search_query': search_query
                }
            elif "è¡Œä¸š" in data_type:
                external_data = {
                    'data_type': 'è¡Œä¸šæ•°æ®',
                    'source': 'æ¨¡æ‹Ÿè¡Œä¸šæŠ¥å‘Š',
                    'summary': f'{content_focus}è¡Œä¸šåˆ†ææŠ¥å‘Š',
                    'key_findings': [
                        'è¡Œä¸šè§„æ¨¡: æŒç»­æ‰©å¤§',
                        'æŠ€æœ¯åˆ›æ–°: AIåº”ç”¨å¢å¤š',
                        'æ”¿ç­–ç¯å¢ƒ: æ”¯æŒæ€§å¼º',
                        'å‘å±•å‰æ™¯: ä¹è§‚å‘å¥½'
                    ],
                    'search_query': search_query
                }
            else:
                external_data = {
                    'data_type': 'ç»¼åˆæ•°æ®',
                    'source': 'æ¨¡æ‹Ÿæ•°æ®æº',
                    'summary': f'å…³äº{search_query}çš„ç»¼åˆä¿¡æ¯',
                    'key_findings': [
                        'æ•°æ®è·å–æˆåŠŸ',
                        'ä¿¡æ¯æ¥æºå¯é ',
                        'æ•°æ®æ—¶æ•ˆæ€§è‰¯å¥½',
                        'è¦†ç›–èŒƒå›´å…¨é¢'
                    ],
                    'search_query': search_query
                }
            
            return {
                'status': 'success',
                'data': external_data,
                'message': f'æˆåŠŸè·å–å¤–éƒ¨æ•°æ®: {data_type}'
            }
            
    except Exception as e:
        return {'status': 'error', 'message': f'å¤–éƒ¨æ•°æ®è·å–å¼‚å¸¸: {str(e)}'}

def execute_llm_analysis_step(step, step_results, llm_client, original_question):
    """æ‰§è¡ŒLLMåˆ†ææ­¥éª¤"""
    analysis_requirements = step.get('analysis_requirements', {})
    
    method = analysis_requirements.get('method', 'ç»¼åˆåˆ†æ')
    input_data_refs = analysis_requirements.get('input_data', [])
    focus_areas = analysis_requirements.get('focus_areas', [])
    insights_target = analysis_requirements.get('insights_target', [])
    
    # æ”¶é›†å‰é¢æ­¥éª¤çš„æ•°æ®
    collected_data = {}
    for data_ref in input_data_refs:
        # å°è¯•åŒ¹é…æ­¥éª¤IDæˆ–æè¿°
        for step_id, result in step_results.items():
            if (str(step_id) in data_ref or 
                any(keyword in data_ref for keyword in [str(step_id), 'æ­¥éª¤', 'step'])):
                collected_data[f"æ­¥éª¤{step_id}"] = result
                break
    
    try:
        # æ„å»ºåˆ†æprompt
        analysis_prompt = f"""è¯·å¯¹ä»¥ä¸‹æ•°æ®è¿›è¡Œ{method}åˆ†æï¼Œå›ç­”åŸå§‹é—®é¢˜ï¼š{original_question}

åˆ†ææ–¹æ³•: {method}
å…³æ³¨é‡ç‚¹: {', '.join(focus_areas)}
æœŸæœ›æ´å¯Ÿ: {', '.join(insights_target)}

å¯ç”¨æ•°æ®:
"""
        
        for data_source, result in collected_data.items():
            analysis_prompt += f"\n{data_source}æ•°æ®:\n"
            if result.get('status') == 'success':
                if isinstance(result.get('data'), pd.DataFrame):
                    # DataFrameè½¬æ¢ä¸ºæ–‡æœ¬æè¿°
                    df = result['data']
                    analysis_prompt += f"æ•°æ®æ¦‚å†µ: {len(df)}è¡Œ x {len(df.columns)}åˆ—\n"
                    analysis_prompt += f"åˆ—å: {', '.join(df.columns)}\n"
                    analysis_prompt += f"æ•°æ®æ ·ä¾‹:\n{df.head(3).to_string()}\n"
                elif result.get('data'):
                    analysis_prompt += f"æ•°æ®å†…å®¹: {str(result['data'])[:500]}...\n"
                else:
                    analysis_prompt += "æ•°æ®ä¸ºç©º\n"
            else:
                analysis_prompt += f"æ•°æ®è·å–å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}\n"
        
        analysis_prompt += f"""

è¯·åŸºäºä»¥ä¸Šæ•°æ®è¿›è¡Œæ·±å…¥åˆ†æï¼Œæä¾›ï¼š
1. æ•°æ®æ¦‚å†µæ€»ç»“
2. å…³é”®å‘ç°å’Œè¶‹åŠ¿
3. é’ˆå¯¹åŸå§‹é—®é¢˜çš„å…·ä½“å›ç­”
4. ä¸šåŠ¡å»ºè®®å’Œæ´å¯Ÿ

è¯·ç¡®ä¿åˆ†æç»“æœå…·ä½“ã€å‡†ç¡®ã€æœ‰ä»·å€¼ã€‚"""
        
        with st.spinner("è¿›è¡ŒAIæ•°æ®åˆ†æ..."):
            analysis_result = llm_client.generate_sql(analysis_prompt)
        
        if analysis_result:
            return {
                'status': 'success',
                'data': analysis_result,
                'message': 'AIåˆ†æå®Œæˆ',
                'analysis_method': method
            }
        else:
            return {'status': 'error', 'message': 'AIåˆ†æç”Ÿæˆå¤±è´¥'}
            
    except Exception as e:
        return {'status': 'error', 'message': f'AIåˆ†æå¼‚å¸¸: {str(e)}'}

def generate_final_analysis_report(plan_content, step_results, execution_log, original_question):
    """ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
    st.markdown("---")
    st.markdown("## ğŸ“Š æœ€ç»ˆåˆ†ææŠ¥å‘Š")
    
    # æŠ¥å‘Šæ¦‚è§ˆ
    successful_steps = sum(1 for result in step_results.values() if result.get('status') == 'success')
    total_steps = len(step_results)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ‰§è¡Œæ­¥éª¤", f"{successful_steps}/{total_steps}")
    with col2:
        st.metric("æˆåŠŸç‡", f"{successful_steps/total_steps*100:.1f}%" if total_steps > 0 else "0%")
    with col3:
        st.metric("åˆ†æç›®æ ‡", "å·²å®Œæˆ" if successful_steps == total_steps else "éƒ¨åˆ†å®Œæˆ")
    
    # åˆ†æç›®æ ‡
    st.subheader("ğŸ¯ åˆ†æç›®æ ‡")
    st.write(plan_content.get('analysis_goal', original_question))
    
    # å…³é”®å‘ç°ï¼ˆä»LLMåˆ†ææ­¥éª¤ä¸­æå–ï¼‰
    llm_analyses = []
    for step_id, result in step_results.items():
        if (result.get('status') == 'success' and 
            result.get('analysis_method') and 
            result.get('data')):
            llm_analyses.append(result['data'])
    
    if llm_analyses:
        st.subheader("ğŸ” å…³é”®å‘ç°")
        for i, analysis in enumerate(llm_analyses):
            st.markdown(f"**åˆ†æ {i+1}:**")
            st.markdown(analysis)
    
    # æ•°æ®æ±‡æ€»
    st.subheader("ğŸ“‹ æ•°æ®æ±‡æ€»")
    for step_id, result in step_results.items():
        if result.get('status') == 'success' and isinstance(result.get('data'), pd.DataFrame):
            st.write(f"**æ­¥éª¤{step_id}æ•°æ®** ({len(result['data'])}è¡Œ)")
            st.dataframe(result['data'].head())
    
    # æ‰§è¡Œæ—¥å¿—
    with st.expander("ğŸ“ è¯¦ç»†æ‰§è¡Œæ—¥å¿—"):
        for log_entry in execution_log:
            st.write(log_entry)

st.set_page_config(page_title="Smart Chat", page_icon="ğŸ’¬", layout="wide")
st.title(t('smart_chat'))

# åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œé…ç½®ç®¡ç†å™¨
mcp_client = MCPClient()
config_manager = ConfigManager()

# åˆå§‹åŒ–èŠå¤©å†å²å’Œåˆ†æçŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_plan" not in st.session_state:
    st.session_state.analysis_plan = None
if "analysis_question" not in st.session_state:
    st.session_state.analysis_question = None

# åˆ›å»ºè¾¹æ 
with st.sidebar:
    st.header(t('settings'))
    
    # æ•°æ®åº“é€‰æ‹©
    database_type = st.selectbox(t('select_database'), ["mysql", "athena"])
    
    # åŠ è½½æ•°æ®åº“é…ç½®
    db_config = config_manager.load_database_config().get(database_type, {})
    if not db_config:
        st.warning(t('config_db_connection_first').format(db_type=database_type.upper()))
    
    # åŠ è½½LLMé…ç½®
    llm_config = config_manager.load_llm_config()
    
    # LLMæ¨¡å‹é€‰æ‹©
    st.subheader(t('llm_model_settings'))
    provider = st.selectbox(
        t('llm_provider'),
        ["openai", "azure_openai", "custom"],
        index=["openai", "azure_openai", "custom"].index(llm_config.get("provider", "openai"))
    )
    
    # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„æ¨¡å‹
    if provider == "openai":
        # ç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ï¼Œæ— éœ€éªŒè¯
        current_model = llm_config.get("openai", {}).get("model", "gpt-4")
        st.info(f"{t('current_using')}: OpenAI - {current_model}")
        # å°†å½“å‰æ¨¡å‹èµ‹å€¼ç»™modelå˜é‡ï¼Œç”¨äºåç»­çš„APIè°ƒç”¨
        model = current_model
    elif provider == "azure_openai":
        deployment = llm_config.get("azure_openai", {}).get("deployment_name", "")
        st.info(f"{t('current_using')}: Azure OpenAI - {deployment}")
    else:  # custom
        model = llm_config.get("custom", {}).get("model", "llama2")
        st.info(f"{t('current_using')}: Custom - {model}")
    
    # å…¶ä»–è®¾ç½®
    st.subheader(t('display_settings'))
    show_schema = st.checkbox(t('show_schema_prompt'), value=True)
    use_llm = st.checkbox(t('use_llm_generate_sql'), value=True)
    
    st.subheader(t('security_settings'))
    check_dangerous_sql = st.checkbox(t('avoid_dangerous_code'), value=True)
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    llm_client = LLMClient(llm_config)

# æ¸²æŸ“æµ‹è¯•é—®é¢˜åŠ©æ‰‹ä¾§è¾¹æ 
render_test_question_sidebar()

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "data" in message:
            try:
                # ç¡®ä¿æ•°æ®ç±»å‹å…¼å®¹æ€§
                df = message["data"]
                if isinstance(df, pd.DataFrame):
                    # è½¬æ¢æ‰€æœ‰åˆ—ä¸ºå­—ç¬¦ä¸²ä»¥é¿å…ç±»å‹å†²çª
                    df_display = df.astype(str)
                    st.dataframe(df_display)
                else:
                    st.dataframe(df)
            except Exception as e:
                st.error(f"æ•°æ®æ˜¾ç¤ºé”™è¯¯: {str(e)}")
                st.write(message["data"])

# è·å–ä¿å­˜çš„è¡¨ç»“æ„ä¿¡æ¯
def get_saved_schema(config_manager, database_type):
    schema_config = config_manager.load_schema_config().get(database_type, {})
    return schema_config.get("tables", {}), schema_config.get("descriptions", {})

# æ„å»ºåŒ…å«schemaçš„prompt
def build_schema_prompt(question, schema_info, table_descriptions):
    prompt = f"""### æ•°æ®åº“æŸ¥è¯¢

ç”¨æˆ·é—®é¢˜: {question}

### æ•°æ®åº“Schema:
"""
    
    for table, table_info in schema_info.items():
        table_desc = table_descriptions.get(table, "")
        prompt += f"\n\nè¡¨: {table}"
        if table_desc:
            prompt += f" - {table_desc}"
        prompt += "\n"
        
        # å¤„ç†ä¸åŒçš„schemaæ ¼å¼
        columns = None
        if isinstance(table_info, dict):
            columns = table_info.get("columns", [])
        elif isinstance(table_info, list):
            columns = table_info
            
        if columns:
            prompt += "| åˆ—å | ç±»å‹ | æè¿° |\n"
            prompt += "| --- | --- | --- |\n"
            for col in columns:
                if isinstance(col, dict):
                    name = col.get("name", "")
                    col_type = col.get("type", "")
                    comment = col.get("comment", "")
                    prompt += f"| {name} | {col_type} | {comment} |\n"
                else:
                    # å¦‚æœcolä¸æ˜¯å­—å…¸ï¼Œç›´æ¥æ·»åŠ 
                    prompt += f"| {col} | - | - |\n"
        else:
            prompt += "è¡¨ç»“æ„ä¿¡æ¯æœªé…ç½®\n"
    
    prompt += "\n\nè¯·æ ¹æ®ç”¨æˆ·é—®é¢˜å’Œæ•°æ®åº“schemaç”ŸæˆSQLæŸ¥è¯¢ã€‚\n\né‡è¦è¦æ±‚ï¼š\n- åªè¿”å›å¯æ‰§è¡Œçš„SQLè¯­å¥\n- ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šè¯´æ˜\n- ä¸è¦æ·»åŠ æ³¨é‡Šæˆ–æè¿°\n- ç›´æ¥è¿”å›SQLä»£ç "
    
    return prompt

# ä½¿ç”¨LLMè¿›è¡Œæ„å›¾è¯†åˆ«
def identify_intent_with_llm(question, llm_client):
    intent_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜çš„æ„å›¾ï¼Œåªè¿”å›ä¸‹åˆ—ä¹‹ä¸€ï¼š
- query: æ•°æ®æŸ¥è¯¢å’ŒåŸºç¡€åˆ†æï¼Œå¯é€šè¿‡SQLæŸ¥è¯¢ç›´æ¥è·å¾—ç»“æœ
- analysis: æ·±åº¦åˆ†æï¼Œéœ€è¦å¤šæ­¥éª¤æ€è€ƒã€åŸå› åˆ†ææˆ–ä¸šåŠ¡æ´å¯Ÿ
- reject: æ¶‰åŠæ•°æ®åº“å¢åˆ æ”¹æ“ä½œ

åˆ†ç±»æ ‡å‡†ï¼š
- query: æ•°æ®æ£€ç´¢ã€æ’åºã€ç»Ÿè®¡è®¡ç®—ã€è¶‹åŠ¿å±•ç¤ºã€å¯¹æ¯”æŸ¥è¯¢ç­‰ï¼Œé‡ç‚¹æ˜¯è·å–å’Œå±•ç¤ºæ•°æ®
- analysis: åŸå› åˆ†æã€æ·±åº¦æ´å¯Ÿã€å¤æ‚æ¨ç†ã€éœ€è¦ä¸šåŠ¡å»ºè®®ç­‰ï¼Œé‡ç‚¹æ˜¯è§£é‡Šå’Œåˆ†æ
- reject: INSERT/UPDATE/DELETE/DROP/CREATE/ALTERç­‰ä¿®æ”¹æ“ä½œ

å‚è€ƒç¤ºä¾‹ï¼š

Queryç±»å‹ï¼ˆæ•°æ®æŸ¥è¯¢å’ŒåŸºç¡€åˆ†æï¼‰ï¼š
- "å“ªäº›äº§å“æ˜¯ç•…é”€å“ï¼Ÿ" â†’ query
- "æ˜¾ç¤ºæ‰€æœ‰ç”¨æˆ·ä¿¡æ¯" â†’ query  
- "æŸ¥è¯¢äº§å“é”€é‡æ’åå‰10å" â†’ query
- "åˆ—å‡º2024å¹´çš„æ‰€æœ‰è®¢å•" â†’ query
- "æŒ‰é”€å”®é¢å¯¹äº§å“è¿›è¡Œæ’åº" â†’ query
- "åˆ†æé”€å”®è¶‹åŠ¿" â†’ query
- "è¿‡å»6ä¸ªæœˆé”€å”®è¶‹åŠ¿å¦‚ä½•ï¼Ÿ" â†’ query
- "åˆ†æäº§å“é”€å”®çš„å­£èŠ‚æ€§è¶‹åŠ¿" â†’ query
- "å¯¹æ¯”ä¸åŒåœ°åŒºçš„é”€å”®è¡¨ç°" â†’ query
- "æ¯”è¾ƒ2023å¹´å’Œ2024å¹´çš„é”€å”®æ•°æ®" â†’ query
- "ç»Ÿè®¡æœˆåº¦å¢é•¿ç‡" â†’ query
- "å“ªä¸ªå­£èŠ‚é”€å”®æœ€å¥½ï¼Ÿ" â†’ query
- "é”€é‡å‰10çš„äº§å“" â†’ query
- "è®¡ç®—å„äº§å“çš„æŠ•èµ„å›æŠ¥ç‡" â†’ query

Analysisç±»å‹ï¼ˆæ·±åº¦åˆ†æå’Œæ´å¯Ÿï¼‰ï¼š
- "ä¸ºä»€ä¹ˆQ4é”€å”®ä¸‹æ»‘ï¼Ÿ" â†’ analysis
- "å®¢æˆ·æµå¤±çš„ä¸»è¦åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ" â†’ analysis
- "åˆ†æåº“å­˜ç§¯å‹çš„æ ¹æœ¬åŸå› " â†’ analysis
- "æ·±å…¥åˆ†æç”¨æˆ·è¡Œä¸ºå˜åŒ–è¶‹åŠ¿" â†’ analysis
- "æ·±åº¦å¯¹æ¯”åˆ†æå„äº§å“çº¿çš„ç›ˆåˆ©èƒ½åŠ›" â†’ analysis
- "è®¡ç®—å®¢æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼" â†’ analysis
- "è¡¨ç°æœ€å·®çš„é”€å”®å‘˜åŠæ”¹è¿›å»ºè®®" â†’ analysis
- "å“ªäº›äº§å“ç•…é”€ï¼Ÿåˆ†æå…¶æˆåŠŸå› ç´ " â†’ analysis
- "ç»Ÿè®¡é”€å”®æ•°æ®å¹¶ç»™å‡ºä¼˜åŒ–å»ºè®®" â†’ analysis
- "å¯¹æ¯”å„åœ°åŒºé”€å”®ï¼Œæ‰¾å‡ºå·®å¼‚åŸå› " â†’ analysis

Rejectç±»å‹ï¼ˆå±é™©æ“ä½œï¼‰ï¼š
- "åˆ é™¤æ‰€æœ‰ç”¨æˆ·æ•°æ®" â†’ reject
- "æ›´æ–°äº§å“ä»·æ ¼" â†’ reject
- "æ’å…¥æ–°çš„è®¢å•è®°å½•" â†’ reject

ç”¨æˆ·é—®é¢˜: {question}

æ„å›¾:"""
    
    try:
        response = llm_client.generate_sql(intent_prompt)
        if response:
            response_lower = response.lower().strip()
            if "reject" in response_lower:
                return "reject"
            elif "analysis" in response_lower:
                return "analysis"
            else:
                return "query"
    except:
        pass
    
    return "query"  # é»˜è®¤è¿”å›æŸ¥è¯¢

# ç”Ÿæˆåˆ†ææ€è·¯
# æ ¼å¼åŒ–JSONè®¡åˆ’çš„æ˜¾ç¤ºå†…å®¹ - ä¸“ä¸ºStreamlitä¼˜åŒ–
def format_json_plan_streamlit(plan_content):
    """å·²åºŸå¼ƒï¼šå¤æ‚æ¸²æŸ“å‡½æ•°ï¼Œç°åœ¨ç›´æ¥ä½¿ç”¨JSONæ˜¾ç¤º"""
    return False

# æ ¼å¼åŒ–JSONè®¡åˆ’çš„Markdownæ˜¾ç¤ºå†…å®¹
def format_json_plan_markdown(plan_content):
    """å°†JSONæ ¼å¼çš„åˆ†æè®¡åˆ’è½¬æ¢ä¸ºMarkdownæ ¼å¼æ˜¾ç¤ºï¼ŒåŒ…å«JSONå’Œå‹å¥½æ­¥éª¤ä¸¤ç§è§†å›¾"""
    import json
    
    try:
        display_lines = []
        
        # æ·»åŠ æ ‡é¢˜å’Œåˆ‡æ¢æç¤º
        display_lines.append("# ğŸ“‹ åˆ†æè®¡åˆ’")
        display_lines.append("")
        display_lines.append("> ä»¥ä¸‹æ˜¯ä¸ºæ‚¨çš„é—®é¢˜åˆ¶å®šçš„ç»“æ„åŒ–åˆ†æè®¡åˆ’ï¼ŒåŒ…å«JSONæ ¼å¼å’Œæ­¥éª¤è¯¦è§£ä¸¤ç§è§†å›¾")
        display_lines.append("")
        
        # JSONæ ¼å¼æ˜¾ç¤º
        display_lines.append("## ğŸ”§ JSONè®¡åˆ’æ ¼å¼")
        display_lines.append("")
        display_lines.append("```json")
        formatted_json = json.dumps(plan_content, ensure_ascii=False, indent=2)
        display_lines.append(formatted_json)
        display_lines.append("```")
        display_lines.append("")
        
        # å‹å¥½çš„æ­¥éª¤æ ¼å¼æ˜¾ç¤º
        display_lines.append("## ğŸ“ æ­¥éª¤è¯¦è§£")
        display_lines.append("")
        
        # åˆ†æç›®æ ‡
        display_lines.append("### ğŸ¯ åˆ†æç›®æ ‡")
        display_lines.append(f"{plan_content.get('analysis_goal', 'æœªå®šä¹‰')}")
        display_lines.append("")
        
        # æ‰§è¡Œæ­¥éª¤
        display_lines.append("### ğŸ”„ æ‰§è¡Œæ­¥éª¤")
        steps = plan_content.get('steps', [])
        
        for step in steps:
            step_id = step.get('step_id', 'N/A')
            step_type = step.get('step_type', 'unknown')
            description = step.get('description', 'æ— æè¿°')
            
            # æ­¥éª¤ç±»å‹å›¾æ ‡å’Œæ ‡ç­¾æ˜ å°„
            type_info = {
                'sql_query': {'emoji': 'ğŸ—„ï¸', 'label': 'æ•°æ®æŸ¥è¯¢'},
                'external_data': {'emoji': 'ğŸŒ', 'label': 'å¤–éƒ¨æ•°æ®'},
                'llm_analysis': {'emoji': 'ğŸ§ ', 'label': 'æ•°æ®åˆ†æ'}
            }
            
            info = type_info.get(step_type, {'emoji': 'ğŸ“‹', 'label': step_type})
            
            display_lines.append(f"#### {info['emoji']} æ­¥éª¤ {step_id}: {info['label']}")
            display_lines.append(f"**æè¿°**: {description}")
            display_lines.append("")
            
            # æ·»åŠ å…·ä½“éœ€æ±‚è¯¦æƒ…
            if step_type == 'sql_query' and 'query_requirements' in step:
                req = step['query_requirements']
                display_lines.append("**æŸ¥è¯¢éœ€æ±‚**:")
                if 'tables' in req and req['tables']:
                    display_lines.append(f"- ğŸ“Š **æ¶‰åŠè¡¨**: `{', '.join(req['tables'])}`")
                if 'time_range' in req:
                    display_lines.append(f"- ğŸ“… **æ—¶é—´èŒƒå›´**: {req['time_range']}")
                if 'filters' in req and req['filters']:
                    display_lines.append(f"- ğŸ” **ç­›é€‰æ¡ä»¶**: {', '.join(req['filters'])}")
                if 'metrics' in req and req['metrics']:
                    metrics_display = ', '.join(req['metrics'][:4])
                    if len(req['metrics']) > 4:
                        metrics_display += f" ç­‰ {len(req['metrics'])} é¡¹æŒ‡æ ‡"
                    display_lines.append(f"- ğŸ“ˆ **å…³é”®æŒ‡æ ‡**: {metrics_display}")
                if 'grouping' in req and req['grouping']:
                    display_lines.append(f"- ğŸ“Š **åˆ†ç»„ç»´åº¦**: {', '.join(req['grouping'])}")
                    
            elif step_type == 'external_data' and 'data_requirements' in step:
                req = step['data_requirements']
                display_lines.append("**æ•°æ®éœ€æ±‚**:")
                if 'data_type' in req:
                    display_lines.append(f"- ğŸŒ¡ï¸ **æ•°æ®ç±»å‹**: {req['data_type']}")
                if 'content_focus' in req:
                    display_lines.append(f"- ğŸ¯ **å…³æ³¨å†…å®¹**: {req['content_focus']}")
                if 'time_scope' in req:
                    display_lines.append(f"- â° **æ—¶é—´èŒƒå›´**: {req['time_scope']}")
                if 'geographic_scope' in req:
                    display_lines.append(f"- ğŸ—ºï¸ **åœ°ç†èŒƒå›´**: {req['geographic_scope']}")
                if 'format_preference' in req:
                    display_lines.append(f"- ğŸ“‹ **æ ¼å¼è¦æ±‚**: {req['format_preference']}")
                    
            elif step_type == 'llm_analysis' and 'analysis_requirements' in step:
                req = step['analysis_requirements']
                display_lines.append("**åˆ†æéœ€æ±‚**:")
                if 'method' in req:
                    display_lines.append(f"- ğŸ”¬ **åˆ†ææ–¹æ³•**: {req['method']}")
                if 'input_data' in req and req['input_data']:
                    display_lines.append(f"- ğŸ“¥ **è¾“å…¥æ•°æ®**: {', '.join(req['input_data'])}")
                if 'focus_areas' in req and req['focus_areas']:
                    areas_display = ', '.join(req['focus_areas'][:3])
                    if len(req['focus_areas']) > 3:
                        areas_display += f" ç­‰ {len(req['focus_areas'])} ä¸ªç»´åº¦"
                    display_lines.append(f"- ğŸ” **å…³æ³¨ç»´åº¦**: {areas_display}")
                if 'comparison_basis' in req:
                    display_lines.append(f"- âš–ï¸ **å¯¹æ¯”åŸºå‡†**: {req['comparison_basis']}")
                if 'insights_target' in req and req['insights_target']:
                    display_lines.append(f"- ğŸ’¡ **ç›®æ ‡æ´å¯Ÿ**: {', '.join(req['insights_target'])}")
            
            # æ˜¾ç¤ºç›®æ ‡æ•°æ®
            if 'target_data' in step:
                display_lines.append(f"- ğŸ¯ **é¢„æœŸæ•°æ®**: {step['target_data']}")
            
            # æ˜¾ç¤ºä¾èµ–å…³ç³»
            dependencies = step.get('dependencies', [])
            if dependencies:
                display_lines.append(f"- ğŸ”— **ä¾èµ–æ­¥éª¤**: æ­¥éª¤ {', '.join(map(str, dependencies))}")
            
            display_lines.append("")
        
        # é¢„æœŸè¾“å‡º
        display_lines.append("### ğŸ“Š é¢„æœŸè¾“å‡º")
        display_lines.append(f"{plan_content.get('expected_output', 'æœªå®šä¹‰')}")
        display_lines.append("")
        
        # æ·»åŠ æ‰§è¡Œæç¤º
        display_lines.append("---")
        display_lines.append("")
        display_lines.append("ğŸ’¡ **ä¸‹ä¸€æ­¥**: è¯·è¾“å…¥ \"æ‰§è¡Œ\" æˆ– \"å¼€å§‹æ‰§è¡Œ\" æ¥å¼€å§‹æŒ‰è®¡åˆ’æ‰§è¡Œåˆ†æ")
        
        return "\n".join(display_lines)
        
    except Exception as e:
        return f"æ ¼å¼åŒ–æ˜¾ç¤ºå‡ºé”™: {str(e)}\n\nåŸå§‹å†…å®¹:\n{str(plan_content)}"

# ä¿ç•™åŸæœ‰ç®€åŒ–ç‰ˆæœ¬ç”¨äºå‘åå…¼å®¹
def format_json_plan_display(plan_content):
    """ç®€åŒ–ç‰ˆæ ¼å¼åŒ–å‡½æ•°ï¼Œç”¨äºå‘åå…¼å®¹"""
    return format_json_plan_markdown(plan_content)

def generate_analysis_plan(question, schema_info, table_descriptions, llm_client):
    plan_prompt = f"""è¯·å°†ä»¥ä¸‹å¤æ‚åˆ†æé—®é¢˜æ‹†åˆ†ä¸ºé€»è¾‘æ¸…æ™°çš„åˆ†ææ­¥éª¤ï¼Œå¹¶ä»¥JSONæ ¼å¼è¾“å‡ºã€‚æ¯ä¸ªæ­¥éª¤åº”è¯¥æè¿°éœ€è¦å®Œæˆçš„ä»»åŠ¡ï¼Œè€Œä¸éœ€è¦æä¾›å…·ä½“çš„å®ç°ç»†èŠ‚ã€‚æ­¥éª¤ç±»å‹åŒ…æ‹¬ï¼š

1. **æ•°æ®æŸ¥è¯¢æ­¥éª¤** (sql_query)
   - æè¿°éœ€è¦ä»æ•°æ®åº“è·å–ä»€ä¹ˆæ•°æ®
   - æ˜ç¡®æŸ¥è¯¢èŒƒå›´ã€ç­›é€‰æ¡ä»¶ã€ç»Ÿè®¡éœ€æ±‚
   - ä¸éœ€è¦ç¼–å†™å…·ä½“SQLè¯­å¥ï¼Œæ‰§è¡Œæ—¶ä¼šæ ¹æ®éœ€æ±‚ç”Ÿæˆ

2. **å¤–éƒ¨æ•°æ®è·å–æ­¥éª¤** (external_data) 
   - æè¿°éœ€è¦è·å–çš„å¤–éƒ¨ä¿¡æ¯ç±»å‹å’Œæ¥æº
   - æ˜ç¡®æ•°æ®è·å–ç›®æ ‡å’Œé¢„æœŸå†…å®¹
   - ä¸éœ€è¦æä¾›å…·ä½“URLæˆ–æŠ€æœ¯ç»†èŠ‚ï¼Œæ‰§è¡Œæ—¶ä¼šç¡®å®šå…·ä½“æ–¹æ¡ˆ

3. **æ•°æ®åˆ†ææ­¥éª¤** (llm_analysis)
   - åŸºäºå‰é¢æ­¥éª¤è·å–çš„æ•°æ®è¿›è¡Œé€»è¾‘æ¨ç†å’Œåˆ†æ
   - æ˜ç¡®åˆ†ææ–¹æ³•ã€å…³æ³¨é‡ç‚¹å’Œè¾“å‡ºè¦æ±‚
   - å®šä¹‰å¦‚ä½•æ•´åˆå¤šæºæ•°æ®å¾—å‡ºç»“è®º

ç”¨æˆ·é—®é¢˜: {question}

å¯ç”¨æ•°æ®åº“è¡¨ç»“æ„:
"""
    
    for table, table_info in schema_info.items():
        table_desc = table_descriptions.get(table, "")
        plan_prompt += f"\nè¡¨: {table}"
        if table_desc:
            plan_prompt += f" - {table_desc}"
        plan_prompt += "\n"
        
        # å¤„ç†ä¸åŒçš„schemaæ ¼å¼
        columns = None
        if isinstance(table_info, dict):
            columns = table_info.get("columns", [])
        elif isinstance(table_info, list):
            columns = table_info
            
        if columns:
            for col in columns:
                if isinstance(col, dict):
                    name = col.get("name", "")
                    col_type = col.get("type", "")
                    comment = col.get("comment", "")
                    plan_prompt += f"  - {name} ({col_type}): {comment}\n"
                else:
                    # å¦‚æœcolä¸æ˜¯å­—å…¸ï¼Œç›´æ¥æ·»åŠ 
                    plan_prompt += f"  - {col}\n"
    
    plan_prompt += """

è¯·ä»¥ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æè®¡åˆ’ï¼š

```json
{
  "analysis_goal": "æ˜ç¡®è¦è§£ç­”çš„æ ¸å¿ƒé—®é¢˜",
  "steps": [
    {
      "step_id": 1,
      "step_type": "sql_query",
      "description": "éœ€è¦æŸ¥è¯¢çš„æ•°æ®å†…å®¹æè¿°",
      "query_requirements": {
        "tables": ["ç›¸å…³çš„æ•°æ®è¡¨å"],
        "time_range": "æ—¶é—´èŒƒå›´è¦æ±‚",
        "filters": ["ç­›é€‰æ¡ä»¶æè¿°"],
        "metrics": ["éœ€è¦çš„æŒ‡æ ‡å’Œç»Ÿè®¡"],
        "grouping": ["åˆ†ç»„ç»´åº¦"]
      },
      "target_data": "é¢„æœŸè·å–çš„æ•°æ®å†…å®¹",
      "dependencies": []
    },
    {
      "step_id": 2,
      "step_type": "external_data",
      "description": "éœ€è¦è·å–çš„å¤–éƒ¨æ•°æ®æè¿°", 
      "data_requirements": {
        "data_type": "æ•°æ®ç±»å‹ (å¤©æ°”/ç»æµ/ç¤¾ä¼šç­‰)",
        "content_focus": "å…³æ³¨çš„å…·ä½“å†…å®¹",
        "time_scope": "æ—¶é—´èŒƒå›´",
        "geographic_scope": "åœ°ç†èŒƒå›´ (å¦‚é€‚ç”¨)",
        "format_preference": "æœŸæœ›çš„æ•°æ®æ ¼å¼"
      },
      "target_data": "é¢„æœŸè·å–çš„å¤–éƒ¨æ•°æ®",
      "dependencies": []
    },
    {
      "step_id": 3,
      "step_type": "llm_analysis",
      "description": "åˆ†æä»»åŠ¡æè¿°",
      "analysis_requirements": {
        "method": "åˆ†ææ–¹æ³• (å…³è”åˆ†æ/è¶‹åŠ¿åˆ†æ/å¯¹æ¯”åˆ†æç­‰)",
        "input_data": ["ä¾èµ–çš„æ­¥éª¤æ•°æ®"],
        "focus_areas": ["é‡ç‚¹å…³æ³¨çš„åˆ†æç»´åº¦"],
        "comparison_basis": "å¯¹æ¯”åŸºå‡†æˆ–å‚è€ƒæ ‡å‡†",
        "insights_target": ["æœŸæœ›å‘ç°çš„æ´å¯Ÿç±»å‹"]
      },
      "output_format": "åˆ†æç»“æœçš„è¾“å‡ºæ ¼å¼",
      "dependencies": [1, 2]
    }
  ],
  "expected_output": "æœ€ç»ˆåˆ†ææŠ¥å‘Šçš„ç»“æ„å’Œå†…å®¹è¦æ±‚"
}
```

**ç¤ºä¾‹** - åˆ†æä¸ºä»€ä¹ˆé›¨è¡£åœ¨4æœˆæ¯”5æœˆé”€é‡å¥½ï¼š

```json
{
  "analysis_goal": "åˆ†æé›¨è¡£4æœˆé”€é‡ä¼˜äº5æœˆçš„åŸå› ï¼Œè¯†åˆ«å…³é”®å½±å“å› ç´ å¹¶æä¾›ä¸šåŠ¡æ´å¯Ÿ",
  "steps": [
    {
      "step_id": 1,
      "step_type": "sql_query",
      "description": "è·å–é›¨è¡£äº§å“4æœˆé”€å”®è¡¨ç°æ•°æ®",
      "query_requirements": {
        "tables": ["sales", "products"],
        "time_range": "2024å¹´4æœˆ",
        "filters": ["äº§å“ç±»åˆ«=é›¨è¡£"],
        "metrics": ["é”€å”®é¢", "è®¢å•æ•°é‡", "å¹³å‡ä»·æ ¼", "äº§å“å‹å·"],
        "grouping": ["äº§å“åç§°", "æ—¥æœŸ"]
      },
      "target_data": "4æœˆé›¨è¡£äº§å“çš„è¯¦ç»†é”€å”®æ•°æ®",
      "dependencies": []
    },
    {
      "step_id": 2,
      "step_type": "sql_query", 
      "description": "è·å–é›¨è¡£äº§å“5æœˆé”€å”®è¡¨ç°æ•°æ®",
      "query_requirements": {
        "tables": ["sales", "products"],
        "time_range": "2024å¹´5æœˆ",
        "filters": ["äº§å“ç±»åˆ«=é›¨è¡£"],
        "metrics": ["é”€å”®é¢", "è®¢å•æ•°é‡", "å¹³å‡ä»·æ ¼", "äº§å“å‹å·"],
        "grouping": ["äº§å“åç§°", "æ—¥æœŸ"]
      },
      "target_data": "5æœˆé›¨è¡£äº§å“çš„è¯¦ç»†é”€å”®æ•°æ®",
      "dependencies": []
    },
    {
      "step_id": 3,
      "step_type": "external_data",
      "description": "è·å–4æœˆå’Œ5æœˆçš„å¤©æ°”æƒ…å†µæ•°æ®",
      "data_requirements": {
        "data_type": "å¤©æ°”æ•°æ®",
        "content_focus": "é™é›¨å¤©æ•°ã€é™é›¨é‡ã€é˜´å¤©æ•°ã€æ¸©åº¦",
        "time_scope": "2024å¹´4æœˆ-5æœˆ",
        "geographic_scope": "é”€å”®è¦†ç›–çš„ä¸»è¦åŸå¸‚",
        "format_preference": "æŒ‰æ—¥ç»Ÿè®¡çš„ç»“æ„åŒ–æ•°æ®"
      },
      "target_data": "4æœˆå’Œ5æœˆçš„å¤©æ°”çŠ¶å†µç»Ÿè®¡",
      "dependencies": []
    },
    {
      "step_id": 4,
      "step_type": "sql_query",
      "description": "è·å–åŒæœŸæ•´ä½“å¸‚åœºé”€å”®æƒ…å†µä½œä¸ºå¯¹æ¯”åŸºå‡†",
      "query_requirements": {
        "tables": ["sales"],
        "time_range": "2024å¹´4æœˆ-5æœˆ",
        "filters": ["æ‰€æœ‰äº§å“ç±»åˆ«"],
        "metrics": ["æ€»é”€å”®é¢", "æ€»è®¢å•æ•°"],
        "grouping": ["æœˆä»½"]
      },
      "target_data": "4æœˆå’Œ5æœˆæ•´ä½“å¸‚åœºè¡¨ç°æ•°æ®",
      "dependencies": []
    },
    {
      "step_id": 5,
      "step_type": "llm_analysis",
      "description": "ç»¼åˆåˆ†æé›¨è¡£é”€é‡æœˆåº¦å·®å¼‚çš„æ ¹æœ¬åŸå› ",
      "analysis_requirements": {
        "method": "å¤šå› ç´ å…³è”åˆ†æå’Œå› æœæ¨ç†",
        "input_data": ["4æœˆé›¨è¡£é”€é‡", "5æœˆé›¨è¡£é”€é‡", "å¤©æ°”æ•°æ®", "å¸‚åœºåŸºå‡†"],
        "focus_areas": ["å¤©æ°”å› ç´ å½±å“", "å­£èŠ‚æ€§æ¶ˆè´¹è§„å¾‹", "äº§å“ç­–ç•¥æ•ˆæœ", "å¸‚åœºç«äº‰æ€åŠ¿"],
        "comparison_basis": "åŒæœŸæ•´ä½“å¸‚åœºè¡¨ç°å’Œå†å²è¶‹åŠ¿",
        "insights_target": ["ä¸»è¦é©±åŠ¨å› ç´ ", "æ”¹è¿›æœºä¼š", "é¢„æµ‹æŒ‡æ ‡"]
      },
      "output_format": "åŒ…å«åŸå› åˆ†æã€æ•°æ®è¯æ®ã€ä¸šåŠ¡å»ºè®®çš„ç»“æ„åŒ–æŠ¥å‘Š",
      "dependencies": [1, 2, 3, 4]
    }
  ],
  "expected_output": "åŒ…å«é”€é‡å·®å¼‚çš„é‡åŒ–åˆ†æã€ä¸»è¦å½±å“å› ç´ è¯†åˆ«ã€å¤©æ°”å…³è”æ€§åˆ†æã€ä»¥åŠé’ˆå¯¹æ€§çš„ä¸šåŠ¡ä¼˜åŒ–å»ºè®®"
}
```

ç°åœ¨è¯·ä¸ºç”¨æˆ·é—®é¢˜ç”Ÿæˆç±»ä¼¼æ ¼å¼çš„JSONåˆ†æè®¡åˆ’ï¼Œç¡®ä¿æ¯ä¸ªæ­¥éª¤éƒ½æœ‰æ˜ç¡®çš„æ‰§è¡Œç›®æ ‡å’Œå…·ä½“çš„å®ç°æ–¹å¼ã€‚

**é‡è¦è¯´æ˜ï¼šè¯·ç›´æ¥è¿”å›æœ‰æ•ˆçš„JSONå¯¹è±¡ï¼Œä¸è¦ä½¿ç”¨markdownä»£ç å—åŒ…è£…ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ã€‚**

ç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§è¿™ä¸ªæ ¼å¼è¿”å›ï¼‰ï¼š
{
  "analysis_goal": "åˆ†æç›®æ ‡æè¿°",
  "steps": [...],
  "expected_output": "é¢„æœŸè¾“å‡ºæè¿°"
}"""
    
    try:
        # å‘é€è¯·æ±‚ç»™LLM
        response = llm_client.generate_sql(plan_prompt)
        
        # å°è¯•è§£æJSONæ ¼å¼çš„å›å¤
        try:
            import json
            
            # é¦–å…ˆå°è¯•ç›´æ¥è§£æJSONï¼ˆLLMç›´æ¥è¿”å›JSONçš„æƒ…å†µï¼‰
            try:
                parsed_plan = json.loads(response)
                
                # éªŒè¯å¿…è¦å­—æ®µ
                required_fields = ['analysis_goal', 'steps', 'expected_output']
                if all(field in parsed_plan for field in required_fields):
                    # è¿”å›ç»“æ„åŒ–çš„è®¡åˆ’
                    return {
                        'format': 'json',
                        'content': parsed_plan,
                        'raw_response': response
                    }
                    
            except json.JSONDecodeError:
                # ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONä»£ç å—ï¼ˆå‘åå…¼å®¹ï¼‰
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                    # éªŒè¯JSONæ ¼å¼
                    parsed_plan = json.loads(json_str)
                    
                    # éªŒè¯å¿…è¦å­—æ®µ
                    required_fields = ['analysis_goal', 'steps', 'expected_output']
                    if all(field in parsed_plan for field in required_fields):
                        # è¿”å›ç»“æ„åŒ–çš„è®¡åˆ’
                        return {
                            'format': 'json',
                            'content': parsed_plan,
                            'raw_response': response
                        }
            
            # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„JSONï¼Œè¿”å›åŸå§‹å“åº”
            return {
                'format': 'text',
                'content': response,
                'raw_response': response
            }
            
        except (json.JSONDecodeError, Exception) as parse_error:
            # JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
            return {
                'format': 'text',
                'content': response,
                'raw_response': response,
                'parse_error': str(parse_error)
            }
            
    except Exception as e:
        return {
            'format': 'error',
            'content': f"ç”Ÿæˆåˆ†æè®¡åˆ’æ—¶å‡ºé”™: {str(e)}",
            'error': str(e)
        }

# ä½¿ç”¨LLMæ£€æµ‹æ˜¯å¦ä¸ºæ‰§è¡Œæ„å›¾
def is_execute_intent_with_llm(question, llm_client):
    execute_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥æ˜¯å¦è¡¨ç¤ºè¦æ‰§è¡Œå½“å‰çš„åˆ†æè®¡åˆ’ï¼š

ç”¨æˆ·è¾“å…¥: {question}

è¯·åªè¿”å›ï¼š
- execute: ç”¨æˆ·è¦æ±‚æ‰§è¡Œåˆ†æè®¡åˆ’
- modify: ç”¨æˆ·è¦æ±‚ä¿®æ”¹æˆ–è¡¥å……è®¡åˆ’

æ„å›¾:"""
    
    try:
        response = llm_client.generate_sql(execute_prompt)
        if response and "execute" in response.lower():
            return True
    except:
        pass
    
    return False

# æ£€æµ‹SQLä¸­çš„å±é™©æ“ä½œ
def check_dangerous_sql_operations(sql):
    dangerous_keywords = [
        'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER', 
        'TRUNCATE', 'REPLACE', 'MERGE', 'GRANT', 'REVOKE'
    ]
    
    sql_upper = sql.upper().strip()
    for keyword in dangerous_keywords:
        if keyword in sql_upper:
            return True, keyword
    return False, None

# SQLç”Ÿæˆå‡½æ•°
def generate_sql(question, database_type, config_manager, llm_client=None, use_llm=False):
    """ä½¿ç”¨LLMç”ŸæˆSQLæŸ¥è¯¢"""
    # è·å–ä¿å­˜çš„schemaä¿¡æ¯
    schema_info, table_descriptions = get_saved_schema(config_manager, database_type)
    
    if not schema_info:
        return None, ""
    
    # æ„å»ºåŒ…å«schemaçš„prompt
    schema_prompt = build_schema_prompt(question, schema_info, table_descriptions)
    
    sql = None
    
    # åªæœ‰å¯ç”¨LLMä¸”æœ‰LLMå®¢æˆ·ç«¯æ—¶æ‰ç”ŸæˆSQL
    if use_llm and llm_client:
        try:
            # è°ƒç”¨LLM APIç”ŸæˆSQL
            llm_response = llm_client.generate_sql(schema_prompt)
            if llm_response:
                # ä»å“åº”ä¸­æå–SQL
                sql_match = re.search(r'```sql\s*([\s\S]*?)\s*```', llm_response)
                if sql_match:
                    sql = sql_match.group(1).strip()
                else:
                    # å°è¯•å…¶ä»–SQLä»£ç å—æ ¼å¼
                    sql_match = re.search(r'```\s*([\s\S]*?)\s*```', llm_response)
                    if sql_match:
                        sql = sql_match.group(1).strip()
                    else:
                        # å¦‚æœæ²¡æœ‰SQLä»£ç å—ï¼Œå°è¯•ç›´æ¥æå–
                        sql = llm_response.strip()
                
                # æ¸…ç†SQLï¼šå»æ‰å¤šä½™çš„è§£é‡Šå†…å®¹
                if sql:
                    sql = clean_sql_response(sql)
        except Exception as e:
            print(f"LLMç”ŸæˆSQLæ—¶å‡ºé”™: {str(e)}")
            sql = None
    
    # è¿”å›ç”Ÿæˆçš„SQLå’ŒåŒ…å«schemaçš„prompt
    return sql, schema_prompt
    
    # è¿”å›ç”Ÿæˆçš„SQLå’ŒåŒ…å«schemaçš„prompt
    return sql, schema_prompt

# æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•é—®é¢˜è¾“å…¥
test_question = get_test_question_input()
if test_question:
    prompt = test_question
else:
    prompt = None

# èŠå¤©è¾“å…¥
if not prompt:
    prompt = st.chat_input(t('enter_question'))

if prompt:
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ç”ŸæˆåŠ©æ‰‹å›å¤
    with st.chat_message("assistant"):
        with st.spinner(t('thinking')):
            if not db_config:
                response = t('config_db_connection_first').format(db_type=database_type.upper())
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„schema
                schema_info, table_descriptions = get_saved_schema(config_manager, database_type)
                
                if not schema_info:
                    response = t('config_schema_first').format(db_type=database_type.upper())
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                else:
                    # æ£€æŸ¥æ˜¯å¦åœ¨åˆ†æè®¡åˆ’é˜¶æ®µ
                    if st.session_state.analysis_plan:
                        # åœ¨åˆ†æè®¡åˆ’é˜¶æ®µï¼Œæ£€æµ‹æ˜¯å¦ä¸ºæ‰§è¡Œæ„å›¾
                        if use_llm and llm_client and is_execute_intent_with_llm(prompt, llm_client):
                            intent = "analysis_execute"
                        else:
                            intent = "analysis_modify"
                    else:
                        # æ­£å¸¸æ„å›¾è¯†åˆ«
                        if use_llm and llm_client:
                            intent = identify_intent_with_llm(prompt, llm_client)
                        else:
                            intent = "query"
                    
                    intent_map = {
                        "query": "æŸ¥è¯¢æ„å›¾",
                        "analysis": "åˆ†ææ„å›¾",
                        "analysis_execute": "åˆ†ææ„å›¾ - æ‰§è¡Œé˜¶æ®µ",
                        "analysis_modify": "åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ",
                        "reject": "æ‹’ç»æ„å›¾"
                    }
                    
                    # å¦‚æœæ˜¯æ‹’ç»æ„å›¾ï¼Œç›´æ¥è¿”å›æ‹’ç»ä¿¡æ¯
                    if intent == "reject":
                        response = f"[æ„å›¾è¯†åˆ«] æ‹’ç»æ„å›¾\n\næŠ±æ­‰ï¼Œä¸ºäº†æ•°æ®å®‰å…¨ï¼Œç³»ç»Ÿä¸æ”¯æŒæ•°æ®åº“çš„å¢åˆ æ”¹æ“ä½œã€‚\nåªæ”¯æŒæ•°æ®æŸ¥è¯¢å’Œåˆ†æåŠŸèƒ½ã€‚"
                        st.markdown(response)
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    elif intent == "analysis_execute":
                        # æ‰§è¡Œåˆ†æè®¡åˆ’ - æ–°çš„æ­¥éª¤åŒ–æ‰§è¡Œé€»è¾‘
                        if st.session_state.analysis_plan and use_llm and llm_client:
                            execute_analysis_plan_steps(
                                st.session_state.analysis_plan,
                                st.session_state.analysis_question,
                                database_type, 
                                config_manager,
                                llm_client,
                                mcp_client,
                                db_config,
                                check_dangerous_sql
                            )
                        else:
                            response = "[æ‰§è¡Œé”™è¯¯] æ²¡æœ‰å¯æ‰§è¡Œçš„åˆ†æè®¡åˆ’æˆ–LLMå®¢æˆ·ç«¯æœªé…ç½®"
                            st.error(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                    elif intent == "analysis_modify":
                        # ä¿®æ”¹åˆ†æè®¡åˆ’
                        if use_llm and llm_client:
                            # æ›´æ–°åˆ†æè®¡åˆ’
                            plan_result = generate_analysis_plan(f"{st.session_state.analysis_question}\n\nç”¨æˆ·è¡¥å……: {prompt}", schema_info, table_descriptions, llm_client)
                            st.session_state.analysis_plan = plan_result
                            
                            # æ ¹æ®è¿”å›æ ¼å¼å¤„ç†æ˜¾ç¤º
                            if isinstance(plan_result, dict):
                                if plan_result.get('format') == 'json':
                                    # JSONæ ¼å¼çš„ç»“æ„åŒ–è®¡åˆ’ - ä½¿ç”¨st.jsonä¼˜åŒ–æ˜¾ç¤º
                                    st.markdown("[æ„å›¾è¯†åˆ«] **åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ** âœ…")
                                    st.success("å·²æ ¹æ®æ‚¨çš„è¡¥å……æ›´æ–°åˆ†æè®¡åˆ’")
                                    
                                    plan_content = plan_result['content']
                                    
                                    # ä½¿ç”¨st.jsonæ˜¾ç¤ºï¼Œæ”¯æŒäº¤äº’å¼å±•å¼€/æŠ˜å 
                                    import json
                                    if isinstance(plan_content, str):
                                        # å¦‚æœæ˜¯JSONå­—ç¬¦ä¸²ï¼Œå…ˆè§£æå†æ˜¾ç¤º
                                        try:
                                            parsed_content = json.loads(plan_content)
                                            st.json(parsed_content, expanded=3)
                                            response_text = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ âœ…\n\nå·²æ›´æ–°åˆ†æè®¡åˆ’ï¼ˆæ”¯æŒäº¤äº’å¼JSONæµè§ˆï¼‰\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                        except json.JSONDecodeError:
                                            # è§£æå¤±è´¥ï¼Œé™çº§åˆ°codeæ˜¾ç¤º
                                            st.code(plan_content, language='json')
                                            response_text = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ âœ…\n\n```json\n{plan_content}\n```\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                    else:
                                        # å¦‚æœæ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨st.json
                                        st.json(plan_content, expanded=3)
                                        response_text = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ âœ…\n\nå·²æ›´æ–°åˆ†æè®¡åˆ’ï¼ˆæ”¯æŒäº¤äº’å¼JSONæµè§ˆï¼‰\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                    
                                    st.info("ğŸ’¡ è¯·è¾“å…¥ \"æ‰§è¡Œ\" æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚")
                                    st.session_state.messages.append({"role": "assistant", "content": response_text})
                                        
                                elif plan_result.get('format') == 'error':
                                    st.error(plan_result['content'])
                                    st.session_state.messages.append({"role": "assistant", "content": f"é”™è¯¯: {plan_result['content']}"})
                                else:
                                    # æ–‡æœ¬æ ¼å¼
                                    response = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ\n\nå·²æ ¹æ®æ‚¨çš„è¡¥å……æ›´æ–°åˆ†æè®¡åˆ’ï¼š\n\n{plan_result['content']}\n\n---\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                    st.markdown(response)
                                    st.session_state.messages.append({"role": "assistant", "content": response})
                            else:
                                # å‘åå…¼å®¹æ—§æ ¼å¼
                                response = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ\n\nå·²æ ¹æ®æ‚¨çš„è¡¥å……æ›´æ–°åˆ†æè®¡åˆ’ï¼š\n\n{str(plan_result)}\n\n---\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                st.markdown(response)
                                st.session_state.messages.append({"role": "assistant", "content": response})
                        else:
                            response = "è¯·å…ˆå¯ç”¨LLMåŠŸèƒ½æ‰èƒ½è¿›è¡Œæ•°æ®åˆ†æ"
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                    elif intent == "analysis":
                        # ç”Ÿæˆåˆ†æè®¡åˆ’
                        if use_llm and llm_client:
                            plan_result = generate_analysis_plan(prompt, schema_info, table_descriptions, llm_client)
                            st.session_state.analysis_plan = plan_result
                            st.session_state.analysis_question = prompt
                            
                            # æ ¹æ®è¿”å›æ ¼å¼å¤„ç†æ˜¾ç¤º
                            if isinstance(plan_result, dict):
                                if plan_result.get('format') == 'json':
                                    # JSONæ ¼å¼çš„ç»“æ„åŒ–è®¡åˆ’ - ä½¿ç”¨st.jsonä¼˜åŒ–æ˜¾ç¤º
                                    st.markdown("[æ„å›¾è¯†åˆ«] **åˆ†ææ„å›¾ - è®¡åˆ’é˜¶æ®µ** âœ…")
                                    st.success("ä»¥ä¸‹æ˜¯ä¸ºæ‚¨çš„åˆ†æé—®é¢˜åˆ¶å®šçš„è®¡åˆ’")
                                    
                                    plan_content = plan_result['content']
                                    
                                    # ä½¿ç”¨st.jsonæ˜¾ç¤ºï¼Œæ”¯æŒäº¤äº’å¼å±•å¼€/æŠ˜å 
                                    import json
                                    if isinstance(plan_content, str):
                                        # å¦‚æœæ˜¯JSONå­—ç¬¦ä¸²ï¼Œå…ˆè§£æå†æ˜¾ç¤º
                                        try:
                                            parsed_content = json.loads(plan_content)
                                            st.json(parsed_content, expanded=3)
                                            response_text = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - è®¡åˆ’é˜¶æ®µ âœ…\n\nå·²ç”Ÿæˆåˆ†æè®¡åˆ’ï¼ˆæ”¯æŒäº¤äº’å¼JSONæµè§ˆï¼‰\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                        except json.JSONDecodeError:
                                            # è§£æå¤±è´¥ï¼Œé™çº§åˆ°codeæ˜¾ç¤º
                                            st.code(plan_content, language='json')
                                            response_text = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - è®¡åˆ’é˜¶æ®µ âœ…\n\n```json\n{plan_content}\n```\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                    else:
                                        # å¦‚æœæ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨st.json
                                        st.json(plan_content, expanded=3)
                                        response_text = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - è®¡åˆ’é˜¶æ®µ âœ…\n\nå·²ç”Ÿæˆåˆ†æè®¡åˆ’ï¼ˆæ”¯æŒäº¤äº’å¼JSONæµè§ˆï¼‰\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                    
                                    st.info("ğŸ’¡ è¯·è¾“å…¥ \"æ‰§è¡Œ\" æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚")
                                    st.session_state.messages.append({"role": "assistant", "content": response_text})
                                        
                                elif plan_result.get('format') == 'error':
                                    st.error(plan_result['content'])
                                    st.session_state.messages.append({"role": "assistant", "content": f"é”™è¯¯: {plan_result['content']}"})
                                else:
                                    # æ–‡æœ¬æ ¼å¼
                                    response = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - è®¡åˆ’é˜¶æ®µ\n\nä»¥ä¸‹æ˜¯ä¸ºæ‚¨çš„åˆ†æé—®é¢˜åˆ¶å®šçš„è®¡åˆ’ï¼š\n\n{plan_result['content']}\n\n---\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                    st.markdown(response)
                                    st.session_state.messages.append({"role": "assistant", "content": response})
                            else:
                                # å‘åå…¼å®¹æ—§æ ¼å¼
                                response = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - è®¡åˆ’é˜¶æ®µ\n\nä»¥ä¸‹æ˜¯ä¸ºæ‚¨çš„åˆ†æé—®é¢˜åˆ¶å®šçš„è®¡åˆ’ï¼š\n\n{str(plan_result)}\n\n---\n\nè¯·è¾“å…¥\"æ‰§è¡Œ\"æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                                st.markdown(response)
                                st.session_state.messages.append({"role": "assistant", "content": response})
                        else:
                            response = "è¯·å…ˆå¯ç”¨LLMåŠŸèƒ½æ‰èƒ½è¿›è¡Œæ•°æ®åˆ†æ"
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                    else:
                        # ç”ŸæˆSQLæŸ¥è¯¢
                        sql, schema_prompt = generate_sql(prompt, database_type, config_manager, llm_client, use_llm)
                        
                        if sql:
                            # æ£€æµ‹å±é™©SQLæ“ä½œ
                            if check_dangerous_sql:
                                is_dangerous, dangerous_keyword = check_dangerous_sql_operations(sql)
                                if is_dangerous:
                                    response = f"[å®‰å…¨æ£€æµ‹] æ£€æµ‹åˆ°å±é™©æ“ä½œ\n\næ£€æµ‹åˆ°SQLä¸­åŒ…å«å±é™©æ“ä½œ: {dangerous_keyword}\nä¸ºäº†æ•°æ®å®‰å…¨ï¼Œç³»ç»Ÿæ‹’ç»æ‰§è¡Œæ­¤æŸ¥è¯¢ã€‚\n\nç”Ÿæˆçš„SQL:\n```sql\n{sql}\n```"
                                    st.markdown(response)
                                    st.session_state.messages.append({"role": "assistant", "content": response})
                                    st.stop()
                            
                            # æ„å»ºå“åº”
                            response_parts = []
                            response_parts.append(f"[æ„å›¾è¯†åˆ«] {intent_map.get(intent, 'æŸ¥è¯¢æ„å›¾')}")
                            response_parts.append(f"æ­£åœ¨ä¸ºæ‚¨æŸ¥è¯¢: {prompt}")
                            response_parts.append(f"æ•°æ®åº“: {database_type}")
                            
                            # æ ¹æ®è®¾ç½®æ˜¾ç¤ºLLMä¿¡æ¯
                            if use_llm:
                                if provider == "openai":
                                    response_parts.append(f"LLM: OpenAI - {llm_config.get('openai', {}).get('model', 'gpt-4')}")
                                elif provider == "azure_openai":
                                    response_parts.append(f"LLM: Azure OpenAI - {llm_config.get('azure_openai', {}).get('deployment_name', '')}")
                                else:  # custom
                                    response_parts.append(f"LLM: è‡ªå®šä¹‰ - {llm_config.get('custom', {}).get('model', 'llama2')}")
                            
                            # æ·»åŠ SQL - ä½¿ç”¨æ›´å®‰å…¨çš„æ ¼å¼åŒ–æ–¹å¼
                            response_parts.append(f"SQL: ")  # å…ˆæ·»åŠ æ ‡ç­¾
                            response_parts.append(f"```sql")  # å•ç‹¬ä¸€è¡Œå¼€å§‹ä»£ç å—
                            response_parts.append(sql)       # æ·»åŠ SQLä»£ç 
                            response_parts.append(f"```")    # å•ç‹¬ä¸€è¡Œç»“æŸä»£ç å—
                            
                            # ç»„åˆå“åº”
                            response = "\n\n".join(response_parts)
                            try:
                                st.markdown(response)
                            except Exception as e:
                                # å¦‚æœmarkdownæ¸²æŸ“å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨çº¯æ–‡æœ¬æ˜¾ç¤º
                                st.text(f"Markdownæ¸²æŸ“å¤±è´¥ï¼Œä»¥ä¸‹æ˜¯åŸå§‹å“åº”:\n{response}")
                                st.error(f"æ¸²æŸ“é”™è¯¯: {str(e)}")
                            
                            # æ ¹æ®è®¾ç½®æ˜¾ç¤ºSchemaæç¤ºï¼ˆä½¿ç”¨å¯æŠ˜å çš„expanderï¼‰
                            if show_schema:
                                with st.expander("ğŸ“‹ æ•°æ®åº“Schemaæç¤º", expanded=False):
                                    st.markdown(f"```\n{schema_prompt}\n```")
                            
                            # æ‰§è¡ŒæŸ¥è¯¢
                            with st.spinner("æ‰§è¡ŒæŸ¥è¯¢ä¸­..."):
                                query_result = mcp_client.call_mcp_server_with_config(
                                    database_type,
                                    "execute_query",
                                    db_config,
                                    {"sql": sql, "database": db_config.get("database")}
                                )
                                
                                if "error" in query_result:
                                    st.error(f"æŸ¥è¯¢å¤±è´¥: {query_result['error']}")
                                    st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢å¤±è´¥: " + query_result['error']})
                                elif "result" in query_result and "data" in query_result["result"]:
                                    # å°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºDataFrame
                                    columns = query_result["result"]["data"].get("columns", [])
                                    rows = query_result["result"]["data"].get("rows", [])
                                    
                                    if rows:
                                        try:
                                            df = pd.DataFrame(rows, columns=columns)
                                            # è½¬æ¢æ‰€æœ‰åˆ—ä¸ºå­—ç¬¦ä¸²ä»¥é¿å…ç±»å‹å†²çª
                                            df_display = df.astype(str)
                                            st.dataframe(df_display)
                                            st.session_state.messages.append({
                                                "role": "assistant", 
                                                "content": response,
                                                "data": df_display
                                            })
                                        except Exception as e:
                                            st.error(f"æ•°æ®æ˜¾ç¤ºé”™è¯¯: {str(e)}")
                                            st.write("åŸå§‹æ•°æ®:", rows)
                                    else:
                                        st.info("æŸ¥è¯¢ç»“æœä¸ºç©º")
                                        st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢ç»“æœä¸ºç©º"})
                                else:
                                    st.warning("æŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®")
                                    st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®"})
                        else:
                            # SQLç”Ÿæˆå¤±è´¥çš„å¤„ç†
                            tables = list(schema_info.keys())
                            
                            if use_llm:
                                # å·²å¯ç”¨LLMä½†ç”Ÿæˆå¤±è´¥
                                response = f"""å¾ˆæŠ±æ­‰ï¼ŒLLMæœªèƒ½ä¸ºæ‚¨çš„é—®é¢˜ç”ŸæˆSQLæŸ¥è¯¢ã€‚

**æ‚¨çš„é—®é¢˜**: {prompt}

**å¯èƒ½çš„åŸå› **:
1. é—®é¢˜æè¿°è¿‡äºå¤æ‚æˆ–æ¨¡ç³Š
2. LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨
3. é—®é¢˜è¶…å‡ºäº†å½“å‰æ•°æ®åº“ç»“æ„çš„æ”¯æŒèŒƒå›´

**å»ºè®®**:
- å°è¯•å°†é—®é¢˜è¡¨è¿°å¾—æ›´å…·ä½“å’Œæ˜ç¡®
- æ£€æŸ¥LLMé…ç½®æ˜¯å¦æ­£ç¡®
- å‚è€ƒå¯ç”¨çš„è¡¨ç»“æ„è°ƒæ•´é—®é¢˜

**å¯ç”¨çš„è¡¨**: {', '.join(tables)}

è¯·é‡æ–°ç»„ç»‡æ‚¨çš„é—®é¢˜ï¼Œæˆ–è”ç³»ç®¡ç†å‘˜æ£€æŸ¥LLMé…ç½®ã€‚"""
                            else:
                                # æœªå¯ç”¨LLM
                                response = f"""ä¸ºäº†å›ç­”æ‚¨çš„é—®é¢˜ "{prompt}"ï¼Œéœ€è¦å¯ç”¨LLMåŠŸèƒ½ã€‚

**å¯ç”¨æ­¥éª¤**:
1. åœ¨é¡µé¢é¡¶éƒ¨å‹¾é€‰"ä½¿ç”¨LLMè¿›è¡ŒSQLç”Ÿæˆ"
2. ç¡®ä¿LLMé…ç½®æ­£ç¡®ï¼ˆåœ¨LLMé…ç½®é¡µé¢è®¾ç½®ï¼‰
3. é‡æ–°æé—®

**å¯ç”¨çš„è¡¨**: {', '.join(tables)}

**è¯´æ˜**: ç³»ç»Ÿç°åœ¨ä»…æ”¯æŒé€šè¿‡LLMç”ŸæˆSQLæŸ¥è¯¢ï¼Œä¸å†æä¾›åŸºäºè§„åˆ™çš„ç®€å•æŸ¥è¯¢åŠŸèƒ½ã€‚"""
                            
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})

# æ¸…é™¤èŠå¤©å†å²
if st.button(t('clear_history')):
    st.session_state.messages = []
    st.rerun()