import streamlit as st
import pandas as pd
import re
from utils.mcp_client import MCPClient
from utils.config_manager import ConfigManager
from utils.llm_client import LLMClient
from utils.i18n import t
from utils.test_question_helper import render_test_question_sidebar, get_test_question_input

def clean_sql_response(sql_text):
    """æ¸…ç†LLMå“åº”ä¸­çš„SQLï¼Œå»æ‰å¤šä½™çš„è§£é‡Šå†…å®¹"""
    if not sql_text:
        return sql_text
    
    lines = sql_text.strip().split('\n')
    sql_lines = []
    
    for line in lines:
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œ
        if not line:
            continue
            
        # è·³è¿‡æ˜æ˜¾çš„è§£é‡Šæ€§æ–‡å­—ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰
        if (line.startswith('ä¸‹é¢çš„') or line.startswith('ä»¥ä¸‹') or 
            line.startswith('This query') or line.startswith('The following') or
            line.startswith('è¿™ä¸ª') or line.startswith('è¯¥') or
            'ä¼šç»Ÿè®¡' in line or 'will calculate' in line or
            'æŒ‰.*æ’åˆ—' in line or 'ordered by' in line.lower() or
            line.startswith('æ³¨æ„ï¼š') or line.startswith('Note:')):
            continue
            
        # è·³è¿‡çº¯ä¸­æ–‡è§£é‡Šè¡Œï¼ˆä¸åŒ…å«SQLå…³é”®å­—ï¼‰
        if (re.match(r'^[^\x00-\x7Fï¼Œã€‚ï¼šï¼›ï¼ï¼Ÿï¼ˆï¼‰ã€ã€‘""''ã€]+[ï¼Œã€‚ï¼šï¼›ï¼ï¼Ÿ]*$', line) and
            not any(keyword in line.upper() for keyword in 
                   ['SELECT', 'FROM', 'WHERE', 'GROUP', 'ORDER', 'INSERT', 'UPDATE', 'DELETE'])):
            continue
            
        # ä¿ç•™SQLè¯­å¥è¡Œ
        sql_lines.append(line)
    
    # é‡æ–°ç»„åˆSQL
    cleaned_sql = '\n'.join(sql_lines).strip()
    
    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œè¿”å›åŸæ–‡
    if not cleaned_sql:
        return sql_text
        
    return cleaned_sql

st.set_page_config(page_title="Smart Chat", page_icon="ğŸ’¬", layout="wide")
st.title(t('smart_chat'))

# åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œé…ç½®ç®¡ç†å™¨
mcp_client = MCPClient()
config_manager = ConfigManager()

# åˆå§‹åŒ–èŠå¤©å†å²å’Œåˆ†æçŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "analysis_plan" not in st.session_state:
    st.session_state.analysis_plan = None
if "analysis_question" not in st.session_state:
    st.session_state.analysis_question = None

# åˆ›å»ºè¾¹æ 
with st.sidebar:
    st.header(t('settings'))
    
    # æ•°æ®åº“é€‰æ‹©
    database_type = st.selectbox(t('select_database'), ["mysql", "athena"])
    
    # åŠ è½½æ•°æ®åº“é…ç½®
    db_config = config_manager.load_database_config().get(database_type, {})
    if not db_config:
        st.warning(t('config_db_connection_first').format(db_type=database_type.upper()))
    
    # åŠ è½½LLMé…ç½®
    llm_config = config_manager.load_llm_config()
    
    # LLMæ¨¡å‹é€‰æ‹©
    st.subheader(t('llm_model_settings'))
    provider = st.selectbox(
        t('llm_provider'),
        ["openai", "azure_openai", "custom"],
        index=["openai", "azure_openai", "custom"].index(llm_config.get("provider", "openai"))
    )
    
    # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„æ¨¡å‹
    if provider == "openai":
        # ç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ï¼Œæ— éœ€éªŒè¯
        current_model = llm_config.get("openai", {}).get("model", "gpt-4")
        st.info(f"{t('current_using')}: OpenAI - {current_model}")
        # å°†å½“å‰æ¨¡å‹èµ‹å€¼ç»™modelå˜é‡ï¼Œç”¨äºåç»­çš„APIè°ƒç”¨
        model = current_model
    elif provider == "azure_openai":
        deployment = llm_config.get("azure_openai", {}).get("deployment_name", "")
        st.info(f"{t('current_using')}: Azure OpenAI - {deployment}")
    else:  # custom
        model = llm_config.get("custom", {}).get("model", "llama2")
        st.info(f"{t('current_using')}: Custom - {model}")
    
    # å…¶ä»–è®¾ç½®
    st.subheader(t('display_settings'))
    show_schema = st.checkbox(t('show_schema_prompt'), value=True)
    use_llm = st.checkbox(t('use_llm_generate_sql'), value=True)
    
    st.subheader(t('security_settings'))
    check_dangerous_sql = st.checkbox(t('avoid_dangerous_code'), value=True)
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    llm_client = LLMClient(llm_config)

# æ¸²æŸ“æµ‹è¯•é—®é¢˜åŠ©æ‰‹ä¾§è¾¹æ 
render_test_question_sidebar()

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "data" in message:
            try:
                # ç¡®ä¿æ•°æ®ç±»å‹å…¼å®¹æ€§
                df = message["data"]
                if isinstance(df, pd.DataFrame):
                    # è½¬æ¢æ‰€æœ‰åˆ—ä¸ºå­—ç¬¦ä¸²ä»¥é¿å…ç±»å‹å†²çª
                    df_display = df.astype(str)
                    st.dataframe(df_display)
                else:
                    st.dataframe(df)
            except Exception as e:
                st.error(f"æ•°æ®æ˜¾ç¤ºé”™è¯¯: {str(e)}")
                st.write(message["data"])

# è·å–ä¿å­˜çš„è¡¨ç»“æ„ä¿¡æ¯
def get_saved_schema(config_manager, database_type):
    schema_config = config_manager.load_schema_config().get(database_type, {})
    return schema_config.get("tables", {}), schema_config.get("descriptions", {})

# æ„å»ºåŒ…å«schemaçš„prompt
def build_schema_prompt(question, schema_info, table_descriptions):
    prompt = f"""### æ•°æ®åº“æŸ¥è¯¢

ç”¨æˆ·é—®é¢˜: {question}

### æ•°æ®åº“Schema:
"""
    
    for table, columns in schema_info.items():
        table_desc = table_descriptions.get(table, "")
        prompt += f"\n\nè¡¨: {table}"
        if table_desc:
            prompt += f" - {table_desc}"
        prompt += "\n"
        
        if columns:
            prompt += "| åˆ—å | ç±»å‹ | æè¿° |\n"
            prompt += "| --- | --- | --- |\n"
            for col in columns:
                name = col.get("name", "")
                col_type = col.get("type", "")
                comment = col.get("comment", "")
                prompt += f"| {name} | {col_type} | {comment} |\n"
        else:
            prompt += "è¡¨ç»“æ„ä¿¡æ¯æœªé…ç½®\n"
    
    prompt += "\n\nè¯·æ ¹æ®ç”¨æˆ·é—®é¢˜å’Œæ•°æ®åº“schemaç”ŸæˆSQLæŸ¥è¯¢ã€‚\n\né‡è¦è¦æ±‚ï¼š\n- åªè¿”å›å¯æ‰§è¡Œçš„SQLè¯­å¥\n- ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šè¯´æ˜\n- ä¸è¦æ·»åŠ æ³¨é‡Šæˆ–æè¿°\n- ç›´æ¥è¿”å›SQLä»£ç "
    
    return prompt

# ä½¿ç”¨LLMè¿›è¡Œæ„å›¾è¯†åˆ«
def identify_intent_with_llm(question, llm_client):
    intent_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜çš„æ„å›¾ï¼Œåªè¿”å›ä¸‹åˆ—ä¹‹ä¸€ï¼š
- query: æ•°æ®æŸ¥è¯¢ï¼ˆåŒ…æ‹¬ç®€å•æŸ¥è¯¢ã€æ’åºæŸ¥è¯¢ã€ç­›é€‰æŸ¥è¯¢ç­‰ï¼‰
- analysis: å¤æ‚çš„æ•°æ®åˆ†æï¼ˆå¦‚ï¼šè¶‹åŠ¿åˆ†æã€å¤šç»´å¯¹æ¯”åˆ†æã€ç»Ÿè®¡è®¡ç®—ã€å…³è”åˆ†æç­‰ï¼‰
- reject: æ¶‰åŠæ•°æ®åº“å¢åˆ æ”¹æ“ä½œï¼ˆINSERT/UPDATE/DELETE/DROP/CREATE/ALTERç­‰ï¼‰

ç”¨æˆ·é—®é¢˜: {question}

åˆ†ç±»æŒ‡å¯¼ï¼š
- queryæ„å›¾ï¼šæŸ¥è¯¢ã€æ˜¾ç¤ºã€åˆ—å‡ºã€å“ªäº›ã€å‰Nåã€æ’åºã€ç­›é€‰ç­‰å•è¡¨æˆ–è€…å¤šè¡¨joinçš„æŸ¥è¯¢éœ€æ±‚ï¼ŒåŒ…æ‹¬è¶‹åŠ¿åˆ†æï¼Œå¤šç»´å¯¹æ¯”ç­‰
- analysisæ„å›¾ï¼šæ— æ³•ä»å•ä¸€queryç»™å‡ºé—®é¢˜çš„ç­”æ¡ˆï¼Œéœ€è¦å…ˆè¿›è¡Œé—®é¢˜æ€ç»´é“¾æ‹†åˆ†åå†é€æ­¥è¿›è¡ŒåŸå› åˆ†æï¼Œå›ç­”'ä¸ºä»€ä¹ˆ'ç­‰å¤æ‚åˆ†æéœ€æ±‚
- rejectæ„å›¾ï¼šä»»ä½•ä¿®æ”¹æ•°æ®çš„æ“ä½œ

ç¤ºä¾‹ï¼š
- "å“ªäº›äº§å“æ˜¯ç•…é”€å“" â†’ queryï¼ˆæŒ‰é”€é‡æ’åºæŸ¥è¯¢ï¼‰
- "æŸ¥è¯¢äº§å“ä¿¡æ¯" â†’ queryï¼ˆç®€å•æŸ¥è¯¢ï¼‰
- "åˆ†æè¿‡å»6ä¸ªæœˆçš„é”€å”®è¶‹åŠ¿å˜åŒ–" â†’ queryï¼ˆè¶‹åŠ¿åˆ†æï¼‰
- "å¯¹æ¯”ä¸åŒåœ°åŒºçš„é”€å”®è¡¨ç°" â†’ queryï¼ˆå¤šç»´å¯¹æ¯”ï¼‰
- "ä¸ºä»€ä¹ˆ2023å¹´çš„è®¢å•å°‘äº2024å¹´" â†’ analysisï¼ˆéœ€è¦åˆ†æåŸå› ï¼‰

æ„å›¾:"""
    
    try:
        response = llm_client.generate_sql(intent_prompt)
        if response:
            response_lower = response.lower().strip()
            if "reject" in response_lower:
                return "reject"
            elif "analysis" in response_lower:
                return "analysis"
            else:
                return "query"
    except:
        pass
    
    return "query"  # é»˜è®¤è¿”å›æŸ¥è¯¢

# ç”Ÿæˆåˆ†ææ€è·¯
def generate_analysis_plan(question, schema_info, table_descriptions, llm_client):
    plan_prompt = f"""è¯·ä¸ºä»¥ä¸‹æ•°æ®åˆ†æé—®é¢˜åˆ¶å®šè¯¦ç»†çš„åˆ†ææ€è·¯å’Œæ­¥éª¤ï¼š

ç”¨æˆ·é—®é¢˜: {question}

æ•°æ®åº“è¡¨ç»“æ„:
"""
    
    for table, columns in schema_info.items():
        table_desc = table_descriptions.get(table, "")
        plan_prompt += f"\nè¡¨: {table}"
        if table_desc:
            plan_prompt += f" - {table_desc}"
        plan_prompt += "\n"
        
        if columns:
            for col in columns:
                name = col.get("name", "")
                col_type = col.get("type", "")
                comment = col.get("comment", "")
                plan_prompt += f"  - {name} ({col_type}): {comment}\n"
    
    plan_prompt += "\n\nè¯·æä¾›ä¸€ä¸ªåˆ†æ­¥éª¤çš„åˆ†æè®¡åˆ’ï¼ŒåŒ…æ‹¬ï¼š\n1. åˆ†æç›®æ ‡\n2. æ‰€éœ€æ•°æ®\n3. åˆ†ææ­¥éª¤\n4. é¢„æœŸç»“æœ"
    
    try:
        response = llm_client.generate_sql(plan_prompt)
        return response
    except Exception as e:
        return f"ç”Ÿæˆåˆ†æè®¡åˆ’æ—¶å‡ºé”™: {str(e)}"

# ä½¿ç”¨LLMæ£€æµ‹æ˜¯å¦ä¸ºæ‰§è¡Œæ„å›¾
def is_execute_intent_with_llm(question, llm_client):
    execute_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥æ˜¯å¦è¡¨ç¤ºè¦æ‰§è¡Œå½“å‰çš„åˆ†æè®¡åˆ’ï¼š

ç”¨æˆ·è¾“å…¥: {question}

è¯·åªè¿”å›ï¼š
- execute: ç”¨æˆ·è¦æ±‚æ‰§è¡Œåˆ†æè®¡åˆ’
- modify: ç”¨æˆ·è¦æ±‚ä¿®æ”¹æˆ–è¡¥å……è®¡åˆ’

æ„å›¾:"""
    
    try:
        response = llm_client.generate_sql(execute_prompt)
        if response and "execute" in response.lower():
            return True
    except:
        pass
    
    return False

# æ£€æµ‹SQLä¸­çš„å±é™©æ“ä½œ
def check_dangerous_sql_operations(sql):
    dangerous_keywords = [
        'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER', 
        'TRUNCATE', 'REPLACE', 'MERGE', 'GRANT', 'REVOKE'
    ]
    
    sql_upper = sql.upper().strip()
    for keyword in dangerous_keywords:
        if keyword in sql_upper:
            return True, keyword
    return False, None

# SQLç”Ÿæˆå‡½æ•°
def generate_sql(question, database_type, config_manager, llm_client=None, use_llm=False):
    """ä½¿ç”¨LLMç”ŸæˆSQLæŸ¥è¯¢"""
    # è·å–ä¿å­˜çš„schemaä¿¡æ¯
    schema_info, table_descriptions = get_saved_schema(config_manager, database_type)
    
    if not schema_info:
        return None, ""
    
    # æ„å»ºåŒ…å«schemaçš„prompt
    schema_prompt = build_schema_prompt(question, schema_info, table_descriptions)
    
    sql = None
    
    # åªæœ‰å¯ç”¨LLMä¸”æœ‰LLMå®¢æˆ·ç«¯æ—¶æ‰ç”ŸæˆSQL
    if use_llm and llm_client:
        try:
            # è°ƒç”¨LLM APIç”ŸæˆSQL
            llm_response = llm_client.generate_sql(schema_prompt)
            if llm_response:
                # ä»å“åº”ä¸­æå–SQL
                sql_match = re.search(r'```sql\s*([\s\S]*?)\s*```', llm_response)
                if sql_match:
                    sql = sql_match.group(1).strip()
                else:
                    # å°è¯•å…¶ä»–SQLä»£ç å—æ ¼å¼
                    sql_match = re.search(r'```\s*([\s\S]*?)\s*```', llm_response)
                    if sql_match:
                        sql = sql_match.group(1).strip()
                    else:
                        # å¦‚æœæ²¡æœ‰SQLä»£ç å—ï¼Œå°è¯•ç›´æ¥æå–
                        sql = llm_response.strip()
                
                # æ¸…ç†SQLï¼šå»æ‰å¤šä½™çš„è§£é‡Šå†…å®¹
                if sql:
                    sql = clean_sql_response(sql)
        except Exception as e:
            print(f"LLMç”ŸæˆSQLæ—¶å‡ºé”™: {str(e)}")
            sql = None
    
    # è¿”å›ç”Ÿæˆçš„SQLå’ŒåŒ…å«schemaçš„prompt
    return sql, schema_prompt
    
    # è¿”å›ç”Ÿæˆçš„SQLå’ŒåŒ…å«schemaçš„prompt
    return sql, schema_prompt

# æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•é—®é¢˜è¾“å…¥
test_question = get_test_question_input()
if test_question:
    prompt = test_question
else:
    prompt = None

# èŠå¤©è¾“å…¥
if not prompt:
    prompt = st.chat_input(t('enter_question'))

if prompt:
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ç”ŸæˆåŠ©æ‰‹å›å¤
    with st.chat_message("assistant"):
        with st.spinner(t('thinking')):
            if not db_config:
                response = t('config_db_connection_first').format(db_type=database_type.upper())
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„schema
                schema_info, table_descriptions = get_saved_schema(config_manager, database_type)
                
                if not schema_info:
                    response = t('config_schema_first').format(db_type=database_type.upper())
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                else:
                    # æ£€æŸ¥æ˜¯å¦åœ¨åˆ†æè®¡åˆ’é˜¶æ®µ
                    if st.session_state.analysis_plan:
                        # åœ¨åˆ†æè®¡åˆ’é˜¶æ®µï¼Œæ£€æµ‹æ˜¯å¦ä¸ºæ‰§è¡Œæ„å›¾
                        if use_llm and llm_client and is_execute_intent_with_llm(prompt, llm_client):
                            intent = "analysis_execute"
                        else:
                            intent = "analysis_modify"
                    else:
                        # æ­£å¸¸æ„å›¾è¯†åˆ«
                        if use_llm and llm_client:
                            intent = identify_intent_with_llm(prompt, llm_client)
                        else:
                            intent = "query"
                    
                    intent_map = {
                        "query": "æŸ¥è¯¢æ„å›¾",
                        "analysis": "åˆ†ææ„å›¾",
                        "analysis_execute": "åˆ†ææ„å›¾ - æ‰§è¡Œé˜¶æ®µ",
                        "analysis_modify": "åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ",
                        "reject": "æ‹’ç»æ„å›¾"
                    }
                    
                    # å¦‚æœæ˜¯æ‹’ç»æ„å›¾ï¼Œç›´æ¥è¿”å›æ‹’ç»ä¿¡æ¯
                    if intent == "reject":
                        response = f"[æ„å›¾è¯†åˆ«] æ‹’ç»æ„å›¾\n\næŠ±æ­‰ï¼Œä¸ºäº†æ•°æ®å®‰å…¨ï¼Œç³»ç»Ÿä¸æ”¯æŒæ•°æ®åº“çš„å¢åˆ æ”¹æ“ä½œã€‚\nåªæ”¯æŒæ•°æ®æŸ¥è¯¢å’Œåˆ†æåŠŸèƒ½ã€‚"
                        st.markdown(response)
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    elif intent == "analysis_execute":
                        # æ‰§è¡Œåˆ†æè®¡åˆ’
                            # æ‰§è¡Œåˆ†æè®¡åˆ’
                            sql, schema_prompt = generate_sql(st.session_state.analysis_question, database_type, config_manager, llm_client, use_llm)
                            
                            if sql:
                                # æ£€æµ‹å±é™©SQLæ“ä½œ
                                if check_dangerous_sql:
                                    is_dangerous, dangerous_keyword = check_dangerous_sql_operations(sql)
                                    if is_dangerous:
                                        response = f"[å®‰å…¨æ£€æµ‹] æ£€æµ‹åˆ°å±é™©æ“ä½œ\n\næ£€æµ‹åˆ°SQLä¸­åŒ…å«å±é™©æ“ä½œ: {dangerous_keyword}\nä¸ºäº†æ•°æ®å®‰å…¨ï¼Œç³»ç»Ÿæ‹’ç»æ‰§è¡Œæ­¤æŸ¥è¯¢ã€‚\n\nç”Ÿæˆçš„SQL:\n```sql\n{sql}\n```"
                                        st.markdown(response)
                                        st.session_state.messages.append({"role": "assistant", "content": response})
                                        st.stop()
                                
                                # æ‰§è¡Œåˆ†ææŸ¥è¯¢
                                response_parts = []
                                response_parts.append(f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - æ‰§è¡Œé˜¶æ®µ")
                                response_parts.append(f"æ­£åœ¨æ‰§è¡Œåˆ†æ: {st.session_state.analysis_question}")
                                response_parts.append(f"æ•°æ®åº“: {database_type}")
                                response_parts.append(f"SQL: \n```sql\n{sql}\n```")
                                
                                response = "\n\n".join(response_parts)
                                st.markdown(response)
                                
                                # æ‰§è¡ŒæŸ¥è¯¢
                                with st.spinner("æ‰§è¡Œåˆ†ææŸ¥è¯¢ä¸­..."):
                                    query_result = mcp_client.call_mcp_server_with_config(
                                        database_type,
                                        "execute_query",
                                        db_config,
                                        {"sql": sql, "database": db_config.get("database")}
                                    )
                                    
                                    if "error" in query_result:
                                        st.error(f"æŸ¥è¯¢å¤±è´¥: {query_result['error']}")
                                        st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢å¤±è´¥: " + query_result['error']})
                                    elif "result" in query_result and "data" in query_result["result"]:
                                        columns = query_result["result"]["data"].get("columns", [])
                                        rows = query_result["result"]["data"].get("rows", [])
                                        
                                        if rows:
                                            try:
                                                df = pd.DataFrame(rows, columns=columns)
                                                # è½¬æ¢æ‰€æœ‰åˆ—ä¸ºå­—ç¬¦ä¸²ä»¥é¿å…ç±»å‹å†²çª
                                                df_display = df.astype(str)
                                                st.dataframe(df_display)
                                                st.session_state.messages.append({
                                                    "role": "assistant", 
                                                    "content": response,
                                                    "data": df_display
                                                })
                                            except Exception as e:
                                                st.error(f"æ•°æ®æ˜¾ç¤ºé”™è¯¯: {str(e)}")
                                                st.write("åŸå§‹æ•°æ®:", rows)
                                        else:
                                            st.info("æŸ¥è¯¢ç»“æœä¸ºç©º")
                                            st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢ç»“æœä¸ºç©º"})
                                    else:
                                        st.warning("æŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®")
                                        st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®"})
                                
                                # æ¸…é™¤åˆ†æè®¡åˆ’
                                st.session_state.analysis_plan = None
                                st.session_state.analysis_question = None
                            else:
                                response = "æ— æ³•ç”Ÿæˆåˆ†æSQLæŸ¥è¯¢"
                                st.markdown(response)
                                st.session_state.messages.append({"role": "assistant", "content": response})
                    elif intent == "analysis_modify":
                        # ä¿®æ”¹åˆ†æè®¡åˆ’
                        if use_llm and llm_client:
                            # æ›´æ–°åˆ†æè®¡åˆ’
                            updated_plan = generate_analysis_plan(f"{st.session_state.analysis_question}\n\nç”¨æˆ·è¡¥å……: {prompt}", schema_info, table_descriptions, llm_client)
                            st.session_state.analysis_plan = updated_plan
                            
                            response = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - ä¿®æ”¹é˜¶æ®µ\n\nå·²æ ¹æ®æ‚¨çš„è¡¥å……æ›´æ–°åˆ†æè®¡åˆ’ï¼š\n\n{updated_plan}\n\n---\n\nè¯·è¾“å…¥â€œæ‰§è¡Œâ€æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                        else:
                            response = "è¯·å…ˆå¯ç”¨LLMåŠŸèƒ½æ‰èƒ½è¿›è¡Œæ•°æ®åˆ†æ"
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                    elif intent == "analysis":
                        # ç”Ÿæˆåˆ†æè®¡åˆ’
                        if use_llm and llm_client:
                            analysis_plan = generate_analysis_plan(prompt, schema_info, table_descriptions, llm_client)
                            st.session_state.analysis_plan = analysis_plan
                            st.session_state.analysis_question = prompt
                            
                            response = f"[æ„å›¾è¯†åˆ«] åˆ†ææ„å›¾ - è®¡åˆ’é˜¶æ®µ\n\nä»¥ä¸‹æ˜¯ä¸ºæ‚¨çš„åˆ†æé—®é¢˜åˆ¶å®šçš„è®¡åˆ’ï¼š\n\n{analysis_plan}\n\n---\n\nè¯·è¾“å…¥â€œæ‰§è¡Œâ€æˆ–ç±»ä¼¼æ„æ€æ¥å¼€å§‹åˆ†æã€‚"
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                        else:
                            response = "è¯·å…ˆå¯ç”¨LLMåŠŸèƒ½æ‰èƒ½è¿›è¡Œæ•°æ®åˆ†æ"
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                    else:
                        # ç”ŸæˆSQLæŸ¥è¯¢
                        sql, schema_prompt = generate_sql(prompt, database_type, config_manager, llm_client, use_llm)
                        
                        if sql:
                            # æ£€æµ‹å±é™©SQLæ“ä½œ
                            if check_dangerous_sql:
                                is_dangerous, dangerous_keyword = check_dangerous_sql_operations(sql)
                                if is_dangerous:
                                    response = f"[å®‰å…¨æ£€æµ‹] æ£€æµ‹åˆ°å±é™©æ“ä½œ\n\næ£€æµ‹åˆ°SQLä¸­åŒ…å«å±é™©æ“ä½œ: {dangerous_keyword}\nä¸ºäº†æ•°æ®å®‰å…¨ï¼Œç³»ç»Ÿæ‹’ç»æ‰§è¡Œæ­¤æŸ¥è¯¢ã€‚\n\nç”Ÿæˆçš„SQL:\n```sql\n{sql}\n```"
                                    st.markdown(response)
                                    st.session_state.messages.append({"role": "assistant", "content": response})
                                    st.stop()
                            
                            # æ„å»ºå“åº”
                            response_parts = []
                            response_parts.append(f"[æ„å›¾è¯†åˆ«] {intent_map.get(intent, 'æŸ¥è¯¢æ„å›¾')}")
                            response_parts.append(f"æ­£åœ¨ä¸ºæ‚¨æŸ¥è¯¢: {prompt}")
                            response_parts.append(f"æ•°æ®åº“: {database_type}")
                            
                            # æ ¹æ®è®¾ç½®æ˜¾ç¤ºLLMä¿¡æ¯
                            if use_llm:
                                if provider == "openai":
                                    response_parts.append(f"LLM: OpenAI - {llm_config.get('openai', {}).get('model', 'gpt-4')}")
                                elif provider == "azure_openai":
                                    response_parts.append(f"LLM: Azure OpenAI - {llm_config.get('azure_openai', {}).get('deployment_name', '')}")
                                else:  # custom
                                    response_parts.append(f"LLM: è‡ªå®šä¹‰ - {llm_config.get('custom', {}).get('model', 'llama2')}")
                            
                            # æ·»åŠ SQL - ä½¿ç”¨æ›´å®‰å…¨çš„æ ¼å¼åŒ–æ–¹å¼
                            response_parts.append(f"SQL: ")  # å…ˆæ·»åŠ æ ‡ç­¾
                            response_parts.append(f"```sql")  # å•ç‹¬ä¸€è¡Œå¼€å§‹ä»£ç å—
                            response_parts.append(sql)       # æ·»åŠ SQLä»£ç 
                            response_parts.append(f"```")    # å•ç‹¬ä¸€è¡Œç»“æŸä»£ç å—
                            
                            # ç»„åˆå“åº”
                            response = "\n\n".join(response_parts)
                            try:
                                st.markdown(response)
                            except Exception as e:
                                # å¦‚æœmarkdownæ¸²æŸ“å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨çº¯æ–‡æœ¬æ˜¾ç¤º
                                st.text(f"Markdownæ¸²æŸ“å¤±è´¥ï¼Œä»¥ä¸‹æ˜¯åŸå§‹å“åº”:\n{response}")
                                st.error(f"æ¸²æŸ“é”™è¯¯: {str(e)}")
                            
                            # æ ¹æ®è®¾ç½®æ˜¾ç¤ºSchemaæç¤ºï¼ˆä½¿ç”¨å¯æŠ˜å çš„expanderï¼‰
                            if show_schema:
                                with st.expander("ğŸ“‹ æ•°æ®åº“Schemaæç¤º", expanded=False):
                                    st.markdown(f"```\n{schema_prompt}\n```")
                            
                            # æ‰§è¡ŒæŸ¥è¯¢
                            with st.spinner("æ‰§è¡ŒæŸ¥è¯¢ä¸­..."):
                                query_result = mcp_client.call_mcp_server_with_config(
                                    database_type,
                                    "execute_query",
                                    db_config,
                                    {"sql": sql, "database": db_config.get("database")}
                                )
                                
                                if "error" in query_result:
                                    st.error(f"æŸ¥è¯¢å¤±è´¥: {query_result['error']}")
                                    st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢å¤±è´¥: " + query_result['error']})
                                elif "result" in query_result and "data" in query_result["result"]:
                                    # å°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºDataFrame
                                    columns = query_result["result"]["data"].get("columns", [])
                                    rows = query_result["result"]["data"].get("rows", [])
                                    
                                    if rows:
                                        try:
                                            df = pd.DataFrame(rows, columns=columns)
                                            # è½¬æ¢æ‰€æœ‰åˆ—ä¸ºå­—ç¬¦ä¸²ä»¥é¿å…ç±»å‹å†²çª
                                            df_display = df.astype(str)
                                            st.dataframe(df_display)
                                            st.session_state.messages.append({
                                                "role": "assistant", 
                                                "content": response,
                                                "data": df_display
                                            })
                                        except Exception as e:
                                            st.error(f"æ•°æ®æ˜¾ç¤ºé”™è¯¯: {str(e)}")
                                            st.write("åŸå§‹æ•°æ®:", rows)
                                    else:
                                        st.info("æŸ¥è¯¢ç»“æœä¸ºç©º")
                                        st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢ç»“æœä¸ºç©º"})
                                else:
                                    st.warning("æŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®")
                                    st.session_state.messages.append({"role": "assistant", "content": response + "\n\næŸ¥è¯¢ç»“æœæ ¼å¼ä¸æ­£ç¡®"})
                        else:
                            # SQLç”Ÿæˆå¤±è´¥çš„å¤„ç†
                            tables = list(schema_info.keys())
                            
                            if use_llm:
                                # å·²å¯ç”¨LLMä½†ç”Ÿæˆå¤±è´¥
                                response = f"""å¾ˆæŠ±æ­‰ï¼ŒLLMæœªèƒ½ä¸ºæ‚¨çš„é—®é¢˜ç”ŸæˆSQLæŸ¥è¯¢ã€‚

**æ‚¨çš„é—®é¢˜**: {prompt}

**å¯èƒ½çš„åŸå› **:
1. é—®é¢˜æè¿°è¿‡äºå¤æ‚æˆ–æ¨¡ç³Š
2. LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨
3. é—®é¢˜è¶…å‡ºäº†å½“å‰æ•°æ®åº“ç»“æ„çš„æ”¯æŒèŒƒå›´

**å»ºè®®**:
- å°è¯•å°†é—®é¢˜è¡¨è¿°å¾—æ›´å…·ä½“å’Œæ˜ç¡®
- æ£€æŸ¥LLMé…ç½®æ˜¯å¦æ­£ç¡®
- å‚è€ƒå¯ç”¨çš„è¡¨ç»“æ„è°ƒæ•´é—®é¢˜

**å¯ç”¨çš„è¡¨**: {', '.join(tables)}

è¯·é‡æ–°ç»„ç»‡æ‚¨çš„é—®é¢˜ï¼Œæˆ–è”ç³»ç®¡ç†å‘˜æ£€æŸ¥LLMé…ç½®ã€‚"""
                            else:
                                # æœªå¯ç”¨LLM
                                response = f"""ä¸ºäº†å›ç­”æ‚¨çš„é—®é¢˜ "{prompt}"ï¼Œéœ€è¦å¯ç”¨LLMåŠŸèƒ½ã€‚

**å¯ç”¨æ­¥éª¤**:
1. åœ¨é¡µé¢é¡¶éƒ¨å‹¾é€‰"ä½¿ç”¨LLMè¿›è¡ŒSQLç”Ÿæˆ"
2. ç¡®ä¿LLMé…ç½®æ­£ç¡®ï¼ˆåœ¨LLMé…ç½®é¡µé¢è®¾ç½®ï¼‰
3. é‡æ–°æé—®

**å¯ç”¨çš„è¡¨**: {', '.join(tables)}

**è¯´æ˜**: ç³»ç»Ÿç°åœ¨ä»…æ”¯æŒé€šè¿‡LLMç”ŸæˆSQLæŸ¥è¯¢ï¼Œä¸å†æä¾›åŸºäºè§„åˆ™çš„ç®€å•æŸ¥è¯¢åŠŸèƒ½ã€‚"""
                            
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})

# æ¸…é™¤èŠå¤©å†å²
if st.button(t('clear_history')):
    st.session_state.messages = []
    st.rerun()